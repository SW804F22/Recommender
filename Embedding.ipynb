{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebedcd1-3b4f-4511-80c5-38fc632073a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Normalizer , scale\n",
    "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2acb48-8b91-453b-a0e1-28b59bbc6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8966183-3de9-4ba3-8250-bd0f9c05cbd6",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "###### Få tal på categories = 1145\n",
    "###### Inkluder categories i dataset\n",
    "###### Lav embedding af categories, som kan bruges som input til netværket\n",
    "###### Ændre i netværk/loss-function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c513afd-13ea-45d2-8d14-a7542907b544",
   "metadata": {},
   "source": [
    "# Create Subset of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7b912-a16b-4fce-8cd1-aeddfc256bd3",
   "metadata": {},
   "source": [
    "## Load in the dataset from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60a8ef0-abfd-496b-b2c8-c391a8893b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: DtypeWarning: Columns (0,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: DtypeWarning: Columns (1,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "checkin_cols = ['user_id', 'poi_id', 'timestamp', 'timezone']\n",
    "checkins = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\TIST2015_Checkins.csv', sep=',', names=checkin_cols, encoding='latin-1')\n",
    "\n",
    "venue_cols = ['poi_id', 'latitude', 'longitude', 'category', 'country_code']\n",
    "pois = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\TIST2015_POIs.csv', sep=',', names=venue_cols, encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32608b7b-013f-44a8-a203-6821719f9a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           poi_id   latitude   longitude           category  \\\n",
      "0                             Pid   Latitude  Longtitude           Category   \n",
      "1        3fd66200f964a52000e71ee3  40.733596  -74.003139          Jazz Club   \n",
      "2        3fd66200f964a52000e81ee3  40.758102  -73.975734                Gym   \n",
      "3        3fd66200f964a52000ea1ee3  40.732456  -74.003755  Indian Restaurant   \n",
      "4        3fd66200f964a52000ec1ee3  42.345907  -71.087001  Indian Restaurant   \n",
      "...                           ...        ...         ...                ...   \n",
      "3680122  5237865c498e89110c1d03e7  40.154444   26.410847        Comedy Club   \n",
      "3680123  5237867411d2a1e910744c81  35.340099   33.309328     Home (private)   \n",
      "3680124  5237879111d216bab10e9e09  -1.404065  -48.453742     Home (private)   \n",
      "3680125  52378c24498ea9502baf2716   3.425155   -76.54501     Sandwich Place   \n",
      "3680126  5237920a11d2173b20b50d4b  -6.129426  106.650974              Plane   \n",
      "\n",
      "        country_code  \n",
      "0            Country  \n",
      "1                 US  \n",
      "2                 US  \n",
      "3                 US  \n",
      "4                 US  \n",
      "...              ...  \n",
      "3680122           TR  \n",
      "3680123           CY  \n",
      "3680124           BR  \n",
      "3680125           CO  \n",
      "3680126           ID  \n",
      "\n",
      "[3680127 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb582d-b794-4092-951d-65811c0dc0e8",
   "metadata": {},
   "source": [
    "## Function that extracts a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81307241-332e-4373-adbc-23c62bfd90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of a dataset with size n users\n",
    "def create_checkin_subset(checkins_table, n):\n",
    "    subset = np.array([[0,0,0,0],[0,0,0,0]])\n",
    "    checkins_100_users = checkins_table['user_id'].sample(n=n, random_state=1)\n",
    "    for i in checkins_100_users:\n",
    "        subset = np.append(subset, np.asarray(checkins_table[checkins_table['user_id'] == i].values), 0)\n",
    "    return pd.DataFrame(subset[2::], columns=['user_id', 'poi_id', 'timestamp', 'timezone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33354896-3b67-4385-ac77-e78e4055fc51",
   "metadata": {},
   "source": [
    "### Calling the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b00722e-8ab8-4d91-a888-af61456ba712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d01f1bcd-57f4-4ef6-beb5-747a4778bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the subset method\n",
    "checkins_100_users = create_checkin_subset(checkins, 25)\n",
    "checkin_data = checkins_100_users.merge(pois, on='poi_id')\n",
    "df = checkin_data.set_index('user_id').poi_id.str.get_dummies(',')\n",
    "df = df.groupby('user_id').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "73214759-d68c-474a-b35e-16dee655aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_data_no_duplicates = checkin_data.copy()\n",
    "checkin_data_no_duplicates.drop_duplicates(subset =\"poi_id\",\n",
    "                     keep = 'first', inplace = True)\n",
    "checkin_data_no_duplicates = pd.DataFrame(checkin_data_no_duplicates, columns = ['poi_id', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a5aef231-50d6-4ec4-ae17-b001190abde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        poi_id           category\n",
      "0     4ef5d479f9ab2e6680a7fdda           Building\n",
      "37    4e621c8d62e13e3bce7bb58d              Diner\n",
      "38    4cb0fb5af2dbef3b6aae79e5              Plaza\n",
      "90    5110b08de4b0d12c384d4e0b              Track\n",
      "91    4d446c883616b60c0435e4c2           Hospital\n",
      "...                        ...                ...\n",
      "9279  4dde6ed4fa769803ef914cb5                Bar\n",
      "9281  4c33694866e40f4727f3c78b         Restaurant\n",
      "9282  4fdd8d30e4b01dfebfe1201b             Bakery\n",
      "9283  5130f6b6e4b090128d2196c3  Convenience Store\n",
      "9285  4f26bec6e4b0d10db2bb003c           Building\n",
      "\n",
      "[2896 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(checkin_data_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198f7a9-1e62-4b7a-b526-c8d81d3a5403",
   "metadata": {},
   "source": [
    "### Extract categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d44275a3-39d2-4b23-bf3c-9cc52a9713fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.DataFrame(checkin_data, columns=['category'])\n",
    "categories.drop_duplicates(subset =\"category\",\n",
    "                     keep = 'first', inplace = True)\n",
    "category_length = len(categories)\n",
    "categories_numpy = categories.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7e519-485a-4217-ab4f-ffe5ab0c0242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_length)\n",
    "print(categories_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "eea55de5-041a-47f3-8cfc-a1f1bc3ce587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(ground_truth, lst):\n",
    "    result = []\n",
    "    for category in lst:\n",
    "        oh_encoding = np.zeros(len(ground_truth))\n",
    "        if category in ground_truth:\n",
    "            print(category)\n",
    "            index = np.where(ground_truth == category)[0][0]\n",
    "            \n",
    "            #Get index og category, and insert 1 into the vector.\n",
    "            result.append(index)\n",
    "    return result\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735eac37-e10d-48db-ade3-24ae15b6227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = one_hot_encode(categories_numpy, categories_numpy)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98ae34-3640-4281-b8f5-7a3e188199d9",
   "metadata": {},
   "source": [
    "## Extracting all of the users and the pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3f456903-18e7-4ee4-8490-ca4f08cbcbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofusers = pd.DataFrame(checkin_data, columns= ['user_id']).groupby('user_id').max().sample(frac=1)\n",
    "listofpois = pd.DataFrame(checkin_data, columns= ['poi_id', 'latitude', 'longitude']).groupby('poi_id').max().sample(frac=1)\n",
    "\n",
    "userarray = listofusers.index.to_numpy()\n",
    "poiarray = listofpois.index.to_numpy()\n",
    "\n",
    "userdataframe = pd.DataFrame(userarray, columns = ['Users'])\n",
    "poidataframe = pd.DataFrame(poiarray, columns = ['Poi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "379a8f92-bd26-4ef3-9375-b922380a79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(userdataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfba402-48b1-4486-a1c7-91b710b9382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDUNDANT, i think\n",
    "\n",
    "rows_list = []\n",
    "for i in range(len(poidataframe)):\n",
    "    longitude = listofpois[listofpois.loc[i, \"Poi\"]]\n",
    "    rows_list.append(dict1)\n",
    "\n",
    "latlong = pd.DataFrame(rows_list) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "850a4d5d-20e1-4a67-9ed2-f884749961cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = userdataframe.merge(poidataframe, how='cross')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5c7a8-13e9-4281-bd5e-4874b4888bbf",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "821d7533-e32d-4b02-aedf-d63d80e967d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           latitude   longitude\n",
      "poi_id                                         \n",
      "4ba72bcaf964a5202d8439e3  35.659598  139.698415\n",
      "4bda5640c79cc928889c7ee9  35.460382  139.628763\n",
      "4b18bed2f964a5207dd523e3  35.702309  139.745032\n",
      "4c7f41fe171b224b106d10b1  35.701256  139.770825\n",
      "4bca0246fb84c9b66d251c3e  -6.166819  106.802948\n",
      "...                             ...         ...\n",
      "4a823f8af964a52001f91fe3   41.94733  -87.653695\n",
      "4b5bab10f964a520e00e29e3  35.689718  139.699252\n",
      "4b466ff5f964a520e82026e3   41.88573   -87.62796\n",
      "51936834498ea46fc3c9f9b7  35.644116  139.748755\n",
      "4b86747ef964a520cc8a31e3  35.452088  139.630673\n",
      "\n",
      "[2896 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(listofpois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8830ef42-101c-404c-805c-1d334220ded1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4e3e05818877b00cfc504604']\n",
      "37.843275\n"
     ]
    }
   ],
   "source": [
    "print([poidataframe.loc[0, \"Poi\"]])\n",
    "print(listofpois.loc['4c576c0ccc96c9b6a70f792e']['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "26deb392-8e1b-450e-985d-02b37cce35a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = dot.loc[i, \"Poi\"]\n",
    "    latitude = listofpois.loc[temp]['latitude']\n",
    "    longitude = listofpois.loc[temp]['longitude']\n",
    "    dict1 = {'latitude':latitude, 'longitude':longitude}\n",
    "    rows_list.append(dict1)\n",
    "    #latitude = poiarray[i]\n",
    "latlong = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e6ee9e7f-44cf-453e-b413-be31a01103e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        latitude   longitude\n",
      "0      35.387608  139.492374\n",
      "1      19.446002  -99.162386\n",
      "2      37.785255   29.084757\n",
      "3      14.554799  121.049209\n",
      "4      38.269416  140.925193\n",
      "...          ...         ...\n",
      "72395  33.418941 -111.925836\n",
      "72396  37.476516  126.981641\n",
      "72397  22.285136  114.157327\n",
      "72398  35.658900  139.703264\n",
      "72399  35.353181  139.531324\n",
      "\n",
      "[72400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(latlong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c4b1f-fed4-42d4-8a13-e50f41b2473c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "76b97c63-6540-41be-8200-b7abf1a4b55d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "userdot = pd.DataFrame(dot, columns= ['Users'])\n",
    "latlong['latitude'] = pd.to_numeric(latlong['latitude'])\n",
    "latlong['longitude'] = pd.to_numeric(latlong['longitude'])\n",
    "dataset = pd.concat([userdot, latlong], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4745117c-c1cf-4fa3-8da6-da151e39ec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72400\n"
     ]
    }
   ],
   "source": [
    "print(len(categories_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d4790-edf1-4500-9047-cbb23c6cd843",
   "metadata": {},
   "source": [
    "## Extracting ground_truth from incidence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "b4dec4d0-95d5-469b-9b45-011cc9c0caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "category_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    dict1 = {'ground_truth':float(temp)}\n",
    "    rows_list.append(dict1)\n",
    "    #Extract category from the list\n",
    "    category = checkin_data_no_duplicates.loc[checkin_data_no_duplicates['poi_id'] == dot.loc[i, \"Poi\"]]\n",
    "    cat = category['category']\n",
    "    index = np.where(categories_numpy == [cat])[0][0]\n",
    "    category_list.append(index)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#category_label = \n",
    "groundtruth = pd.DataFrame(rows_list)\n",
    "#result = pd.concat([dot, groundtruth], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d88e85b1-b3b2-4707-8e2d-a5c72901bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.DataFrame(category_list, columns=['category'])\n",
    "datasetst = pd.concat([dataset, categories], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "019859cb-94e4-41c4-8145-f23dad6949ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Users   latitude   longitude  category\n",
      "0      43298  35.659598  139.698415       139\n",
      "1      43298  35.460382  139.628763        18\n",
      "2      43298  35.702309  139.745032        86\n",
      "3      43298  35.701256  139.770825        94\n",
      "4      43298  -6.166819  106.802948        18\n",
      "...      ...        ...         ...       ...\n",
      "72395   9765  41.947330  -87.653695        86\n",
      "72396   9765  35.689718  139.699252        86\n",
      "72397   9765  41.885730  -87.627960        86\n",
      "72398   9765  35.644116  139.748755        95\n",
      "72399   9765  35.452088  139.630673        18\n",
      "\n",
      "[72400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(datasetst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "763eceef-a5a8-41a6-afa0-acb08a33ffc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_numpy = datasetst.to_numpy()\n",
    "labels_numpy = groundtruth.to_numpy()\n",
    "categories_numpy = categories.to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_numpy, labels_numpy, test_size=0.05, random_state=0)\n",
    "\n",
    "x_train_df = pd.DataFrame(x_train, columns=['User','Latitude','Longitude', '0'])\n",
    "x_test_df = pd.DataFrame(x_test, columns=['User','Latitude','Longitude', '0'])\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "#Dataset with Users\n",
    "dataset1_df = pd.DataFrame(x_train_df['User'])\n",
    "\n",
    "#Dataset with Poi's\n",
    "dataset2_df = pd.DataFrame(x_train_df[['Latitude', 'Longitude']])\n",
    "\n",
    "dataset3_df = pd.DataFrame(x_train_df[['0']])\n",
    "\n",
    "\n",
    "dataset1 = tf.convert_to_tensor(\n",
    "    dataset1_df, dtype=None, dtype_hint=None, name=None)\n",
    "dataset2 = tf.convert_to_tensor(\n",
    "    dataset2_df, dtype=None, dtype_hint=None, name=None)\n",
    "dataset3 = tf.convert_to_tensor(\n",
    "    dataset3_df, dtype='int64', dtype_hint=None, name=None)\n",
    "labels = tf.convert_to_tensor(\n",
    "    y_train_df, dtype=None, dtype_hint=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "33f1ae64-9cab-41d3-b0d4-74124b2001c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  2]\n",
      " [ 43]\n",
      " [117]\n",
      " ...\n",
      " [176]\n",
      " [  0]\n",
      " [ 86]], shape=(68780, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a978e995-e5ba-4b42-a003-6f07f6a98d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbModel(Model):\n",
    "    def __init__(self, poilength, useridlength, category_length):\n",
    "        super(EmbModel, self).__init__()\n",
    "        self.d_steps = 1\n",
    "        self.poilength = poilength\n",
    "        self.useridlength = useridlength\n",
    "        self.category_length = category_length\n",
    "        self.model = self.init_model()\n",
    "        print(self.useridlength)\n",
    "        print(self.poilength)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return\n",
    "    \n",
    "    def init_model(self):\n",
    "        poi_latitude_input = keras.Input(shape=(1,), name='poi_latitude')\n",
    "        poi_longitude_input = keras.Input(shape=(1,), name='poi_longitude')\n",
    "        poi_concat_input = tf.keras.layers.Concatenate(axis=-1)([poi_latitude_input, poi_longitude_input])\n",
    "        #input_length:  #This is the length of input sequences, as you would define for any input layer of a Keras model. \n",
    "                        #For example, if all of your input documents are comprised of 1000 words, this would be 1000\n",
    "        #input_dim: \n",
    "                        #This is the size of the vocabulary in the text data. \n",
    "                        #For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "        poi_dense = layers.Dense(128)(poi_concat_input)\n",
    "        poi_reshape = layers.Reshape((1, 128))(poi_dense)\n",
    "        \n",
    "        category_input = keras.Input(shape=(1), name='category_input')\n",
    "        category_emb = layers.Embedding(self.category_length, 128)(category_input)\n",
    "        \n",
    "        category_concat = tf.keras.layers.Concatenate(axis=-1)([category_emb, poi_reshape])\n",
    "    \n",
    "        user_input = keras.Input(shape=(1,), name='user_id')\n",
    "        #user_dense = keras.layers.Dense(2)(user_input)\n",
    "        user_emb = layers.Dense(256)(user_input)\n",
    "        user_reshape = layers.Reshape((1, 256))(user_emb)\n",
    "        \n",
    "                                    \n",
    "        dot = layers.Dot(axes=(2))([category_concat, user_reshape])\n",
    "        \n",
    "        \n",
    "        model = Model([category_input, [poi_latitude_input, poi_longitude_input], user_input], dot)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def compile_model(self, optimizer):\n",
    "        super(EmbModel, self).compile(run_eagerly=True)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        if len(data) == 3:\n",
    "            real_data, labels, sample_weight = data\n",
    "        else:\n",
    "            sample_weight = None\n",
    "            real_data, labels = data\n",
    "        user_data = real_data[0]\n",
    "        latlong_data = real_data[1]\n",
    "        cat_data = real_data[2]\n",
    "        print(user_data)\n",
    "        print(latlong_data)\n",
    "        print(cat_data)\n",
    "        \n",
    "        for i in range(self.d_steps):\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                \n",
    "                #print(latlong_data[0])\n",
    "                #print(latlong_data[1])\n",
    "                #print(user_data)\n",
    "                \n",
    "                dotproduct = self.model([cat_data, [latlong_data[0], latlong_data[1]], user_data])\n",
    "                #print(dotproduct)\n",
    "                # Loss function = ||S-GroundTruth|| \n",
    "                loss = tf.math.abs(tf.subtract(tf.cast(dotproduct, tf.float64), labels))\n",
    "                #print(loss)\n",
    "            d_gradient = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(d_gradient, self.model.trainable_variables))\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def predict_step(self, data):\n",
    "        sample_weight = None\n",
    "        real_data = data[0]\n",
    "        user_data = real_data[0]\n",
    "        latlong_data = real_data[1]\n",
    "        return self.model([[latlong_data[0], latlong_data[1]], user_data])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "600fa95d-8cdb-446f-97e9-49c88c0da31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(userdataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "950bec32-baf7-43b9-9ab1-b3443c46ab4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "poi_latitude (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "poi_longitude (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 2)            0           poi_latitude[0][0]               \n",
      "                                                                 poi_longitude[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "category_input (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 128)          384         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 1, 128)       9267328     category_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1, 128)       0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          512         user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 1, 256)       0           embedding_45[0][0]               \n",
      "                                                                 reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_22 (Reshape)            (None, 1, 256)       0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, 1, 1)         0           concatenate_40[0][0]             \n",
      "                                                                 reshape_22[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 9,268,224\n",
      "Trainable params: 9,268,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "1000\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "model = EmbModel(100, 1000, len(categories_numpy)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8dc98d15-f5c8-48b7-a161-b0562c684ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Tensor(\"IteratorGetNext:0\", shape=(2, 1), dtype=float64)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(2, 2), dtype=float64)\n",
      "Tensor(\"IteratorGetNext:2\", shape=(2, 1), dtype=int64)\n",
      "Tensor(\"IteratorGetNext:0\", shape=(2, 1), dtype=float64)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(2, 2), dtype=float64)\n",
      "Tensor(\"IteratorGetNext:2\", shape=(2, 1), dtype=int64)\n",
      " 9110/34390 [======>.......................] - ETA: 40:42 - loss: 57139.2977 ETA"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-359-82530a90022f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Train_data, [dataset.user_id, dataset.poi_id]. Label: ground_truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "model.compile(\n",
    "    optimizer\n",
    ")\n",
    "\n",
    "#Train_data, [dataset.user_id, dataset.poi_id]. Label: ground_truth\n",
    "model.fit([dataset1, dataset2, dataset3], labels, epochs = 20, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d2b63-47d6-45ff-bff5-862989f06e4c",
   "metadata": {},
   "source": [
    "# Tests - Works using x_test_df and checkin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba07da67-d9e5-4eed-a00e-ffaf0fab83f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 123.0889\n",
      "The user has visited the PoI\n",
      "Score: 25.664396\n",
      "The user has visited the PoI\n",
      "Score: 194.60417\n",
      "The user has visited the PoI\n",
      "Score: -126.65549\n",
      "The user has visited the PoI\n",
      "Score: 67.29813\n",
      "The user has visited the PoI\n",
      "Score: -86.97806\n",
      "The user has visited the PoI\n",
      "Score: -86.963356\n",
      "The user has visited the PoI\n",
      "Score: -242.43178\n",
      "The user has visited the PoI\n",
      "Score: -5.513416\n",
      "The user has visited the PoI\n",
      "Score: -242.22806\n",
      "The user has visited the PoI\n",
      "Score: -143.27936\n",
      "The user has visited the PoI\n",
      "Score: 229.01755\n",
      "The user has visited the PoI\n",
      "Score: 229.00754\n",
      "The user has visited the PoI\n",
      "Score: 107.062004\n",
      "The user has visited the PoI\n",
      "Score: -5.677358\n",
      "The user has visited the PoI\n",
      "Score: 123.14945\n",
      "The user has visited the PoI\n",
      "Score: -171.49234\n",
      "The user has visited the PoI\n",
      "Score: 85.168594\n",
      "The user has visited the PoI\n",
      "Score: 1.3155111\n",
      "The user has visited the PoI\n",
      "Score: -126.538124\n",
      "The user has visited the PoI\n",
      "Score: 1.3146948\n",
      "The user has visited the PoI\n",
      "Score: 154.58261\n",
      "The user has visited the PoI\n",
      "Score: -138.99356\n",
      "The user has visited the PoI\n",
      "Score: -651.4547\n",
      "The user has visited the PoI\n",
      "Score: -5.68435\n",
      "The user has visited the PoI\n",
      "Score: -449.85294\n",
      "The user has visited the PoI\n",
      "Score: 107.17579\n",
      "The user has visited the PoI\n",
      "Score: -5.6712737\n",
      "The user has visited the PoI\n",
      "Score: -98.23878\n",
      "The user has visited the PoI\n",
      "Score: -138.99615\n",
      "The user has visited the PoI\n",
      "Score: -126.36697\n",
      "The user has visited the PoI\n",
      "Score: -126.581215\n",
      "The user has visited the PoI\n",
      "Score: 107.056854\n",
      "The user has visited the PoI\n",
      "Score: -86.94912\n",
      "The user has visited the PoI\n",
      "Score: 85.233475\n",
      "The user has visited the PoI\n",
      "Score: -86.92513\n",
      "The user has visited the PoI\n",
      "Score: -279.11667\n",
      "The user has visited the PoI\n",
      "Score: -20.341455\n",
      "The user has visited the PoI\n",
      "Score: 119.69617\n",
      "The user has visited the PoI\n",
      "Score: -143.43561\n",
      "The user has visited the PoI\n",
      "Score: 67.238304\n",
      "The user has visited the PoI\n",
      "Score: -126.689186\n",
      "The user has visited the PoI\n",
      "Score: -29.014166\n",
      "The user has visited the PoI\n",
      "Score: -86.96281\n",
      "The user has visited the PoI\n",
      "Score: 85.174446\n",
      "The user has visited the PoI\n",
      "Score: 1.3156481\n",
      "The user has visited the PoI\n",
      "Score: 228.94485\n",
      "The user has visited the PoI\n",
      "Score: 85.18432\n",
      "The user has visited the PoI\n",
      "Score: -143.26074\n",
      "The user has visited the PoI\n",
      "Score: 107.33349\n",
      "The user has visited the PoI\n",
      "Score: -29.079273\n",
      "The user has visited the PoI\n",
      "Score: -448.87915\n",
      "The user has visited the PoI\n",
      "Score: -133.33388\n",
      "The user has visited the PoI\n",
      "Score: 85.22102\n",
      "The user has visited the PoI\n",
      "Score: -366.25818\n",
      "The user has visited the PoI\n",
      "Score: 194.58682\n",
      "The user has visited the PoI\n",
      "Score: -309.4693\n",
      "The user has visited the PoI\n",
      "Score: -651.4578\n",
      "The user has visited the PoI\n",
      "Score: 1.3146336\n",
      "The user has visited the PoI\n",
      "Score: 232.89085\n",
      "The user has visited the PoI\n",
      "Score: 85.16893\n",
      "The user has visited the PoI\n",
      "Score: 1.3180317\n",
      "The user has visited the PoI\n",
      "Score: -98.23964\n",
      "The user has visited the PoI\n",
      "Score: -143.30751\n",
      "The user has visited the PoI\n",
      "Score: -279.11798\n",
      "The user has visited the PoI\n",
      "Score: -5.692628\n",
      "The user has visited the PoI\n",
      "Score: -126.53824\n",
      "The user has visited the PoI\n",
      "Score: 54.517967\n",
      "The user has visited the PoI\n",
      "Score: 107.14096\n",
      "The user has visited the PoI\n",
      "Score: 107.0741\n",
      "The user has visited the PoI\n",
      "Score: 1.9454846\n",
      "The user has visited the PoI\n",
      "Score: 155.39061\n",
      "The user has visited the PoI\n",
      "Score: -22.291887\n",
      "The user has visited the PoI\n",
      "Score: -651.463\n",
      "The user has visited the PoI\n",
      "Score: -86.93961\n",
      "The user has visited the PoI\n",
      "Score: -125.44082\n",
      "The user has visited the PoI\n",
      "Score: -5.3337617\n",
      "The user has visited the PoI\n",
      "Score: 228.86275\n",
      "The user has visited the PoI\n",
      "Score: 1.315175\n",
      "The user has visited the PoI\n",
      "Score: 228.87329\n",
      "The user has visited the PoI\n",
      "Score: -242.33124\n",
      "The user has visited the PoI\n",
      "Score: 1.316493\n",
      "The user has visited the PoI\n",
      "Score: -98.38871\n",
      "The user has visited the PoI\n",
      "Score: 107.12922\n",
      "The user has visited the PoI\n",
      "Score: 1.3156563\n",
      "The user has visited the PoI\n",
      "Score: -5.6731057\n",
      "The user has visited the PoI\n",
      "Score: -125.445335\n",
      "The user has visited the PoI\n",
      "Score: -366.28186\n",
      "The user has visited the PoI\n",
      "Score: -5.570722\n",
      "The user has visited the PoI\n",
      "Score: -1884.8435\n",
      "The user has visited the PoI\n",
      "Score: -5.6823034\n",
      "The user has visited the PoI\n",
      "Score: -125.43536\n",
      "The user has visited the PoI\n",
      "Score: 85.17445\n",
      "The user has visited the PoI\n",
      "Score: 25.65895\n",
      "The user has visited the PoI\n",
      "Score: -366.29865\n",
      "The user has visited the PoI\n",
      "Score: 157.46492\n",
      "The user has visited the PoI\n",
      "Score: -143.31526\n",
      "The user has visited the PoI\n",
      "Score: -432.79694\n",
      "The user has visited the PoI\n",
      "Score: -86.92675\n",
      "The user has visited the PoI\n",
      "Score: -5.672757\n",
      "The user has visited the PoI\n",
      "Score: 107.06002\n",
      "The user has visited the PoI\n",
      "Score: 107.06282\n",
      "The user has visited the PoI\n",
      "Score: -126.10583\n",
      "The user has visited the PoI\n",
      "Score: -133.35191\n",
      "The user has visited the PoI\n",
      "Score: -543.3033\n",
      "The user has visited the PoI\n",
      "Score: 107.77458\n",
      "The user has visited the PoI\n",
      "Score: 229.04967\n",
      "The user has visited the PoI\n",
      "Score: 85.16997\n",
      "The user has visited the PoI\n",
      "Score: -126.62698\n",
      "The user has visited the PoI\n",
      "Score: 165.16057\n",
      "The user has visited the PoI\n",
      "Score: 229.1006\n",
      "The user has visited the PoI\n",
      "Score: -86.95621\n",
      "The user has visited the PoI\n",
      "Score: -5.3328347\n",
      "The user has visited the PoI\n",
      "Score: -143.25803\n",
      "The user has visited the PoI\n",
      "Score: -125.44285\n",
      "The user has visited the PoI\n",
      "Score: 228.77899\n",
      "The user has visited the PoI\n",
      "Score: -0.4371917\n",
      "The user has visited the PoI\n",
      "Score: -5.67116\n",
      "The user has visited the PoI\n",
      "Score: -98.23359\n",
      "The user has visited the PoI\n",
      "Score: -621.132\n",
      "The user has visited the PoI\n",
      "Score: -5.675979\n",
      "The user has visited the PoI\n"
     ]
    }
   ],
   "source": [
    "x_test_df['User'] = x_test_df['User'].astype('int')\n",
    "x_test_df['User'] = pd.to_numeric(x_test_df['User'])\n",
    "for index, row in x_test_df.iterrows():\n",
    "    \n",
    "    test = checkin_data.loc[\n",
    "        (checkin_data['user_id'] == x_test_df.loc[index, 'User']) & \n",
    "        (checkin_data['latitude'] == x_test_df.loc[index, 'Latitude']) & \n",
    "        (checkin_data['longitude'] == x_test_df.loc[index, 'Longitude'])]\n",
    "    \n",
    "    if test.empty:\n",
    "        visited = 0\n",
    "    else:\n",
    "        visited = 1\n",
    "        \n",
    "    if visited == 0:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    long = tf.convert_to_tensor([row['Longitude']],dtype=None, dtype_hint=None, name=None)\n",
    "    lat = tf.convert_to_tensor([row['Latitude']],dtype=None, dtype_hint=None, name=None)\n",
    "    user = tf.convert_to_tensor([row['User']],dtype=None, dtype_hint=None, name=None)\n",
    "    score = model.predict([user, [long, lat]])\n",
    "    print(\"Score:\", score[0][0])\n",
    "    if visited == 1:\n",
    "        print(\"The user has visited the PoI\")\n",
    "    else:\n",
    "        print(\"The user has not visited the PoI \\n\")\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5111b-18c8-40a3-baa1-2c2101df6368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc1451-ace5-4746-9fb5-7a95ea069800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
