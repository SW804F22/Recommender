{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e9f1c4e-ad77-47cf-a7b6-99ed1d3c0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4948f5-6f42-495c-a809-a6255c83d503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "296b3506-696f-4dae-bca4-f620d5883333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbModel(tf.keras.Model):\n",
    "    def __init__(self, useridlength, category_length):\n",
    "        super(EmbModel, self).__init__()\n",
    "        self.d_steps = 1\n",
    "        self.useridlength = useridlength\n",
    "        self.category_length = category_length\n",
    "        self.model = self.init_model()\n",
    "        print(self.useridlength)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return\n",
    "    \n",
    "    def init_model(self):\n",
    "        poi_latitude_input = keras.layers.Input(shape=(1,), name='poi_latitude')\n",
    "        poi_longitude_input = keras.layers.Input(shape=(1,), name='poi_longitude')\n",
    "        poi_concat_input = tf.keras.layers.Concatenate(axis=-1)([poi_latitude_input, poi_longitude_input])\n",
    "        #input_length:  #This is the length of input sequences, as you would define for any input layer of a Keras model. \n",
    "                        #For example, if all of your input documents are comprised of 1000 words, this would be 1000\n",
    "        #input_dim: \n",
    "                        #This is the size of the vocabulary in the text data. \n",
    "                        #For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "        poi_dense = keras.layers.Dense(128)(poi_concat_input)\n",
    "        poi_reshape = keras.layers.Reshape((1, 128))(poi_dense)\n",
    "        \n",
    "        category_input = keras.layers.Input(shape=(1), name='category_input')\n",
    "        category_emb = keras.layers.Embedding(self.category_length, 128)(category_input)    \n",
    "        category_concat = tf.keras.layers.Concatenate(axis=-1)([category_emb, poi_reshape])\n",
    "    \n",
    "        user_input = keras.layers.Input(shape=(1,), name='user_id')\n",
    "        user_emb = keras.layers.Embedding(self.useridlength, 256)(user_input)\n",
    "        #user_reshape = layers.Reshape((1, 256))(user_emb)\n",
    "                                    \n",
    "        dot = keras.layers.Dot(axes=(2))([category_concat, user_emb])\n",
    "            \n",
    "        model = Model([category_input, poi_latitude_input, poi_longitude_input, user_input], dot)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def compile_model(self, optimizer):\n",
    "        super(EmbModel, self).compile(run_eagerly=True)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        sample_weight = None\n",
    "        real_data = data\n",
    "        user_data = real_data[0]\n",
    "        lat_data = real_data[1]\n",
    "        long_data = real_data[2]\n",
    "        labels = real_data[3]\n",
    "        cat_data = real_data[4]\n",
    "        \n",
    "\n",
    "        for i in range(self.d_steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                \n",
    "                #print(latlong_data[0])\n",
    "                #print(latlong_data[1])\n",
    "                #print(user_data)\n",
    "                \n",
    "                dotproduct = self.model([cat_data, lat_data, long_data, user_data])\n",
    "                print(dotproduct)\n",
    "                #print(dotproduct)\n",
    "                # Loss function = ||S-GroundTruth|| \n",
    "                loss = tf.math.abs(tf.subtract(tf.cast(dotproduct, tf.float64), labels))\n",
    "                #print(loss)\n",
    "            d_gradient = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(d_gradient, self.model.trainable_variables))\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.out_units)\n",
    "    \n",
    "    def predict_step(self, data):\n",
    "        sample_weight = None\n",
    "        cat_data = real_data[0]\n",
    "        lat_data = real_data[1]\n",
    "        long_data = real_data[2]\n",
    "        user_data = real_data[3]\n",
    "        return self.model([cat_data, lat_data, long_data, user_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e675789b-a124-43c8-948c-f97fe94f34e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[100.        55.62852   12.647297   0.       147.      ]\n",
      " [139.        55.703993  12.538325   0.        89.      ]\n",
      " [ 80.        55.674379  12.55062    0.       224.      ]\n",
      " ...\n",
      " [ 19.        55.677101  12.57536    0.       114.      ]\n",
      " [ 16.        55.629631  12.64919    0.        10.      ]\n",
      " [ 31.        55.677083  12.58322    0.       175.      ]], shape=(26239, 5), dtype=float64)\n",
      "Model: \"functional_43\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "poi_latitude (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "poi_longitude (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 2)            0           poi_latitude[0][0]               \n",
      "                                                                 poi_longitude[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "category_input (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 128)          384         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 1, 128)       35712       category_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_21 (Reshape)            (None, 1, 128)       0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 1, 256)       0           embedding_42[0][0]               \n",
      "                                                                 reshape_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 1, 256)       246528      user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_21 (Dot)                    (None, 1, 1)         0           concatenate_43[0][0]             \n",
      "                                                                 embedding_43[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 282,624\n",
      "Trainable params: 282,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "963\n",
      "Epoch 1/25\n",
      "Tensor(\"functional_43/dot_21/MatMul:0\", shape=(5, 1, 1), dtype=float32)\n",
      "Tensor(\"functional_43/dot_21/MatMul:0\", shape=(5, 1, 1), dtype=float32)\n",
      "  1/972 [..............................] - ETA: 0s - loss: 144.2249"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[0,0] = 515 is not in [0, 279)\n\t [[node functional_43/embedding_42/embedding_lookup (defined at <ipython-input-96-54b6d30e8c01>:60) ]] [Op:__inference_train_function_20373]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_43/embedding_42/embedding_lookup:\n functional_43/embedding_42/embedding_lookup/20190 (defined at C:\\Users\\lasse\\anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-a0b35fe71e1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#Train_data, [dataset.user_id, dataset.poi_id]. Label: ground_truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[0,0] = 515 is not in [0, 279)\n\t [[node functional_43/embedding_42/embedding_lookup (defined at <ipython-input-96-54b6d30e8c01>:60) ]] [Op:__inference_train_function_20373]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node functional_43/embedding_42/embedding_lookup:\n functional_43/embedding_42/embedding_lookup/20190 (defined at C:\\Users\\lasse\\anaconda3\\lib\\contextlib.py:113)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "model = EmbModel(len(users), category_length)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "model.compile(\n",
    "    optimizer\n",
    ")\n",
    "\n",
    "#Train_data, [dataset.user_id, dataset.poi_id]. Label: ground_truth\n",
    "model.fit(dataset, epochs = 25, batch_size=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce1ec999-3d31-4491-87b4-5a268abb7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(ground_truth, lst):\n",
    "    result = []\n",
    "    for category in lst:\n",
    "        oh_encoding = np.zeros(len(ground_truth))\n",
    "        if category in ground_truth:\n",
    "            print(category)\n",
    "            index = np.where(ground_truth == category)[0][0]\n",
    "            \n",
    "            #Get index og category, and insert 1 into the vector.\n",
    "            result.append(index)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a58bafa-812c-4aa4-b502-edaa81e1fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkins\n",
      "Loading POIs\n",
      "Checkins:  10473\n",
      "Users:  963\n",
      "Gotten:  9510\n",
      "Unique categories in checkins_rest:  279\n",
      "Total categories:  279\n",
      "Overview:\n",
      "963\n",
      "279\n",
      "9228\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading checkins\")\n",
    "checkin_cols = ['user_id', 'poi_id', 'timestamp', 'timezone']\n",
    "checkins = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\Den_checkins.csv', sep=',', names=checkin_cols, encoding='latin-1').dropna(axis=1)\n",
    "\n",
    "print(\"Loading POIs\")\n",
    "venue_cols = ['poi_id', 'latitude', 'longitude', 'category', 'country_code']\n",
    "pois = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\Den_pois.csv', sep=',', names=venue_cols, encoding='latin-1')\n",
    "\n",
    "c = pd.DataFrame(checkins, columns=['user_id', 'poi_id'])\n",
    "p = pd.DataFrame(pois, columns=['poi_id', 'latitude', 'longitude', 'category'])\n",
    "\n",
    "cp = p.merge(c, on='poi_id')\n",
    "\n",
    "#One checkin for each user\n",
    "users = checkins.copy()\n",
    "users.drop_duplicates(subset=\"user_id\", keep = 'first', inplace = True)\n",
    "print(\"Checkins: \", len(checkins))\n",
    "print(\"Users: \", len(users))\n",
    "len_checkins = len(checkins)\n",
    "len_users = len(users)\n",
    "\n",
    "#The rest of the checkins and categories\n",
    "checkins_rest = users.merge(checkins, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='right_only']\n",
    "print(\"Gotten: \", len(checkins_rest))\n",
    "\n",
    "#One of each category in checkins_rest\n",
    "categories1 = pd.DataFrame(pois, columns=['poi_id', 'category'])\n",
    "categories1 = checkins_rest.merge(categories1, on='poi_id')\n",
    "users_categories1 = categories1.copy()\n",
    "users_categories1.drop_duplicates(subset=\"category\", keep = 'first', inplace = True)\n",
    "print(\"Unique categories in checkins_rest: \", len(users_categories1))\n",
    "\n",
    "#FINISHING NOTE: Vi vil have alle colplement af checkins_rest, når vi sammenligner med categories_cat_no_cat, så har vi de 3 gange checkins vi har brug for. Så kan vi lave train/test på det store af dem.\n",
    "categories_cat_no_cat = pd.DataFrame(users_categories1, columns=['user_id', 'poi_id', 'timestamp', 'timezone', 'category'])\n",
    "checkins_rest_no_merge = pd.DataFrame(checkins_rest, columns=['user_id', 'poi_id', 'timestamp', 'timezone'])\n",
    "poisandcategories = pd.DataFrame(pois, columns=['poi_id', 'category'])\n",
    "checkins_rest_no_merge = checkins_rest_no_merge.merge(poisandcategories, on='poi_id')\n",
    "print(\"Total categories: \", len(categories_cat_no_cat))\n",
    "\n",
    "test = categories_cat_no_cat.merge(checkins_rest_no_merge, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='right_only']\n",
    "#test = pd.DataFrame(checkins_rest, columns=['user_id', 'poi_id', 'timestamp', 'timezone'])\n",
    "#cattest = pd.DataFrame(pois, columns=['poi_id', 'category'])\n",
    "#test.merge(cattest, on='poi_id')\n",
    "#checkins_rest = cattest.merge(test, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='right_only']\n",
    "\n",
    "restset = pd.DataFrame(test, columns=['user_id', 'poi_id', 'timestamp', 'timezone'])\n",
    "userset = users\n",
    "categoryset = pd.DataFrame(users_categories1, columns=['user_id', 'poi_id', 'timestamp', 'timezone'])\n",
    "\n",
    "print(\"Overview:\")\n",
    "print(len(userset))\n",
    "print(len(categoryset))\n",
    "print(len(restset))\n",
    "\n",
    "encoding = pd.DataFrame(userset, columns=['user_id'])\n",
    "#print(encoding)\n",
    "encoding_array = {}\n",
    "temp = 0\n",
    "for user in encoding.iterrows():\n",
    "    user = user[0]\n",
    "    value = encoding._get_value(user, 'user_id')\n",
    "    encoding_array[value] = temp\n",
    "    temp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008a9dd-7186-437c-b3c7-faccd7cb2dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25cd959c-8d10-45c2-b004-b0b8f84036ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 3.5\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "###################################\n",
    "####### Iteration 1: User #########\n",
    "###################################\n",
    "###################################\n",
    "\n",
    "print(\"Step 1\")\n",
    "checkin_data = categoryset.merge(pois, on='poi_id')\n",
    "#checkin_data.drop_duplicates(subset=\"user_id\", keep = 'first', inplace = True)\n",
    "\n",
    "df = checkin_data.set_index('user_id').poi_id.str.get_dummies(',')\n",
    "df = df.groupby('user_id').max()\n",
    "\n",
    "print(\"Step 2\")\n",
    "checkin_data_no_duplicates = checkin_data.copy()\n",
    "checkin_data_no_duplicates.drop_duplicates(subset =\"poi_id\", keep = 'first', inplace = True)\n",
    "checkin_data_no_duplicates = pd.DataFrame(checkin_data_no_duplicates, columns = ['poi_id', 'category'])\n",
    "\n",
    "#Extract categorical data\n",
    "print(\"Step 3\")\n",
    "categories = pd.DataFrame(checkin_data, columns=['category'])\n",
    "categories.drop_duplicates(subset =\"category\", keep = 'first', inplace = True)\n",
    "category_length = len(categories)\n",
    "categories_numpy = categories.to_numpy()\n",
    "\n",
    "\n",
    "#Extracting all of the users and the pois\n",
    "\n",
    "print(\"Step 3.5\")\n",
    "listofusers = pd.DataFrame(checkin_data, columns= ['user_id']).groupby('user_id').max().sample(frac=1)\n",
    "listofpois = pd.DataFrame(checkin_data, columns= ['poi_id', 'latitude', 'longitude']).groupby('poi_id').max().sample(frac=1)\n",
    "userarray = listofusers.index.to_numpy()\n",
    "poiarray = listofpois.index.to_numpy()\n",
    "userdataframe = pd.DataFrame(userarray, columns = ['Users'])\n",
    "poidataframe = pd.DataFrame(poiarray, columns = ['Poi'])\n",
    "dot = userdataframe.merge(poidataframe, how='cross')\n",
    "\n",
    "print(\"Step 4\")\n",
    "\n",
    "rows_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = dot.loc[i, \"Poi\"]\n",
    "    latitude = listofpois.loc[temp]['latitude']\n",
    "    longitude = listofpois.loc[temp]['longitude']\n",
    "    dict1 = {'latitude':latitude, 'longitude':longitude}\n",
    "    rows_list.append(dict1)\n",
    "    #latitude = poiarray[i]\n",
    "latlong = pd.DataFrame(rows_list)\n",
    "\n",
    "#Creating dataset\n",
    "print(\"Step 5\")\n",
    "userdot = pd.DataFrame(dot, columns= ['Users'])\n",
    "latlong['latitude'] = pd.to_numeric(latlong['latitude'])\n",
    "latlong['longitude'] = pd.to_numeric(latlong['longitude'])\n",
    "dataset = pd.concat([userdot, latlong], axis=1)\n",
    "\n",
    "print(\"Step 6\")\n",
    "rows_list = []\n",
    "category_list = []\n",
    "groundtruth = 0\n",
    "for i in range(len(dot)):\n",
    "    temp = cp.loc[(cp['poi_id'] == dot.loc[i, \"Poi\"]) & (cp['user_id'] == dot.loc[i, \"Users\"])]\n",
    "    if temp.empty:\n",
    "        groundtruth = 0\n",
    "    else:\n",
    "        groundtruth = 1\n",
    "    #temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    #temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    dict1 = {'ground_truth':float(groundtruth)}\n",
    "    rows_list.append(dict1)\n",
    "    #Extract category from the list\n",
    "    category = checkin_data_no_duplicates.loc[checkin_data_no_duplicates['poi_id'] == dot.loc[i, \"Poi\"]]\n",
    "    cat = category['category']\n",
    "    index = np.where(categories_numpy == [cat])[0][0]\n",
    "    category_list.append(index)\n",
    "#category_label = \n",
    "groundtruth = pd.DataFrame(rows_list)\n",
    "#result = pd.concat([dot, groundtruth], axis=1)\n",
    "\n",
    "print(\"Step 7\")\n",
    "datasetst = pd.concat([dataset, groundtruth], axis=1)\n",
    "categories = pd.DataFrame(category_list, columns=['category'])\n",
    "datasetstst = pd.concat([datasetst, categories], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "724bc008-0346-4fd5-9e60-865da6b2d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\categories_numpy.npy\", categories_numpy)\n",
    "#d2=np.load(r\"C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\d1.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a93527f8-d532-4324-a10d-8406d0eef38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Users   latitude  longitude  ground_truth  category\n",
      "0      159853  55.693507  12.541721           0.0        30\n",
      "1      159853  55.698009  12.474439           0.0       272\n",
      "2      159853  55.628672  12.644426           0.0       219\n",
      "3      159853  55.699679  12.536593           0.0       170\n",
      "4      159853  55.738396  12.571651           0.0        82\n",
      "...       ...        ...        ...           ...       ...\n",
      "27616  164326  55.646972  12.541492           0.0       119\n",
      "27617  164326  55.672940  12.564495           0.0       128\n",
      "27618  164326  55.680127  12.560722           0.0        98\n",
      "27619  164326  55.685796  12.568576           0.0       155\n",
      "27620  164326  55.695400  12.609100           0.0       267\n",
      "\n",
      "[27621 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(datasetstst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c4ff1eb-a3c3-4980-b863-01b66532ec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR \" == 0\"\n",
      "18456\n",
      "71191.0\n",
      "55.737798\n",
      "12.522954\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for index, row in datasetstst.iterrows():\n",
    "    long = float(datasetstst.loc[index, 'longitude'])\n",
    "    lat = float(datasetstst.loc[index, 'latitude'])\n",
    "    user = float(datasetstst.loc[index, 'Users'])\n",
    "    cat = float(datasetstst.loc[index, 'category'])\n",
    "    groundtruth = datasetstst.loc[index, 'ground_truth']\n",
    "    \n",
    "    if groundtruth == 0:\n",
    "        test = cp.loc[(cp['user_id'] == user) & (cp['latitude'] == lat) & (cp['longitude'] == long)]\n",
    "        boolean = test.empty\n",
    "        if not boolean:\n",
    "            print(\"ERROR \\\" == 0\\\"\")\n",
    "            print(index)\n",
    "            print(user)\n",
    "            print(lat)\n",
    "            print(long)\n",
    "            print(groundtruth)\n",
    "            \n",
    "    elif groundtruth == 1:\n",
    "        test = cp.loc[(cp['user_id'] == user) & (cp['latitude'] == lat) & (cp['longitude'] == long)]\n",
    "        boolean = test.empty\n",
    "        if boolean:\n",
    "            print(test)\n",
    "            print(\"ERROR \\\" == 1\\\"\")\n",
    "            print(index)\n",
    "            print(user)\n",
    "            print(lat)\n",
    "            print(long)\n",
    "            print(groundtruth)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b49de473-1e33-494d-98e0-f326b460aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo\n"
     ]
    }
   ],
   "source": [
    "print(\"yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecd84b-096d-473e-9926-9333e454d0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb1c8619-67e2-49a4-bdb0-f100569b3a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Users   latitude  longitude  ground_truth  category\n",
      "0       12123  55.681057  12.524736           0.0       152\n",
      "1       12123  55.678870  12.579392           0.0       263\n",
      "2       12123  55.593808  12.640104           0.0       275\n",
      "3       12123  55.679661  12.582324           0.0       109\n",
      "4       12123  55.662761  12.601849           0.0       227\n",
      "...       ...        ...        ...           ...       ...\n",
      "27616  230978  55.685796  12.568576           0.0       155\n",
      "27617  230978  55.719278  12.551812           0.0        60\n",
      "27618  230978  55.646972  12.541492           0.0       119\n",
      "27619  230978  55.679399  12.572565           0.0        46\n",
      "27620  230978  55.684848  12.538001           0.0       189\n",
      "\n",
      "[27621 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "    temp = cp.loc[(cp['poi_id'] == dot.loc[i, \"Poi\"]) & (cp['user_id'] == dot.loc[i, \"Users\"])]\n",
    "    if temp.empty:\n",
    "        groundtruth = 0\n",
    "    else:\n",
    "        groundtruth = 1\n",
    "    #temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "901784e9-5265-4333-a626-7935ba5f71fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8\n",
      "Step 9\n",
      "Step 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Step 8\")\n",
    "dataset_numpy = datasetstst.to_numpy()\n",
    "\n",
    "print(\"Step 9\")\n",
    "x_train_df = pd.DataFrame(dataset_numpy, columns=['Users', 'latitude', 'longitude', 'ground_truth', 'category'])\n",
    "\n",
    "for index, row in x_train_df.iterrows():\n",
    "    usr = x_train_df.loc[index, 'Users']\n",
    "    x_train_df.xs(index)['Users']=encoding_array.get(usr)\n",
    "\n",
    "print(\"Step 10\")\n",
    "dataset = tf.convert_to_tensor(\n",
    "    x_train_df, dtype=None, dtype_hint=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "98725e7b-3c69-41d0-8764-9a1be4216878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           User   Latitude  Longitude      0\n",
      "0       80758.0  55.679661  12.582324  109.0\n",
      "1       80758.0  55.731908  12.575850   84.0\n",
      "2       80758.0  55.681057  12.524736  152.0\n",
      "3       80758.0  55.731910  12.483522    1.0\n",
      "4       80758.0  55.673021  12.554590  136.0\n",
      "...         ...        ...        ...    ...\n",
      "27616  141345.0  55.752348  12.571790  172.0\n",
      "27617  141345.0  55.670639  12.541494  237.0\n",
      "27618  141345.0  55.788225  12.530318   83.0\n",
      "27619  141345.0  55.626090  12.478889  228.0\n",
      "27620  141345.0  55.668386  12.551174   75.0\n",
      "\n",
      "[27621 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efb88a6c-f5c9-4c83-ac98-c9411a86650a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'restset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-32f492d6cfee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Step 1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcheckin_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpois\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'poi_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#checkin_data.drop_duplicates(subset=\"user_id\", keep = 'first', inplace = True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckin_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoi_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'restset' is not defined"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "###################################\n",
    "####### Iteration 1: User #########\n",
    "###################################\n",
    "###################################\n",
    "\n",
    "print(\"Step 1\")\n",
    "checkin_data = restset.merge(pois, on='poi_id')\n",
    "#checkin_data.drop_duplicates(subset=\"user_id\", keep = 'first', inplace = True)\n",
    "df = checkin_data.set_index('user_id').poi_id.str.get_dummies(',')\n",
    "df = df.groupby('user_id').max()\n",
    "\n",
    "print(\"Step 2\")\n",
    "checkin_data_no_duplicates = checkin_data.copy()\n",
    "checkin_data_no_duplicates.drop_duplicates(subset =\"poi_id\", keep = 'first', inplace = True)\n",
    "checkin_data_no_duplicates = pd.DataFrame(checkin_data_no_duplicates, columns = ['poi_id', 'category'])\n",
    "\n",
    "#Extract categorical data\n",
    "print(\"Step 3\")\n",
    "categories = pd.DataFrame(checkin_data, columns=['category'])\n",
    "categories.drop_duplicates(subset =\"category\", keep = 'first', inplace = True)\n",
    "category_length = len(categories)\n",
    "categories_numpy = categories.to_numpy()\n",
    "\n",
    "\n",
    "#Extracting all of the users and the pois\n",
    "print(\"Step 3.5\")\n",
    "listofusers = pd.DataFrame(checkin_data, columns= ['user_id']).groupby('user_id').max().sample(frac=1)\n",
    "listofpois = pd.DataFrame(checkin_data, columns= ['poi_id', 'latitude', 'longitude']).groupby('poi_id').max().sample(frac=1)\n",
    "userarray = listofusers.index.to_numpy()\n",
    "poiarray = listofpois.index.to_numpy()\n",
    "userdataframe = pd.DataFrame(userarray, columns = ['Users'])\n",
    "poidataframe = pd.DataFrame(poiarray, columns = ['Poi'])\n",
    "dot = userdataframe.merge(poidataframe, how='cross')\n",
    "\n",
    "print(\"Step 4\")\n",
    "rows_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = dot.loc[i, \"Poi\"]\n",
    "    latitude = listofpois.loc[temp]['latitude']\n",
    "    longitude = listofpois.loc[temp]['longitude']\n",
    "    dict1 = {'latitude':latitude, 'longitude':longitude}\n",
    "    rows_list.append(dict1)\n",
    "    #latitude = poiarray[i]\n",
    "latlong = pd.DataFrame(rows_list)\n",
    "\n",
    "#Creating dataset\n",
    "print(\"Step 5\")\n",
    "userdot = pd.DataFrame(dot, columns= ['Users'])\n",
    "latlong['latitude'] = pd.to_numeric(latlong['latitude'])\n",
    "latlong['longitude'] = pd.to_numeric(latlong['longitude'])\n",
    "dataset = pd.concat([userdot, latlong], axis=1)\n",
    "\n",
    "#Extracting ground_truth from incidence matrix\n",
    "print(\"Step 6\")\n",
    "rows_list = []\n",
    "category_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    dict1 = {'ground_truth':float(temp)}\n",
    "    rows_list.append(dict1)\n",
    "    #Extract category from the list\n",
    "    category = checkin_data_no_duplicates.loc[checkin_data_no_duplicates['poi_id'] == dot.loc[i, \"Poi\"]]\n",
    "    cat = category['category']\n",
    "    index = np.where(categories_numpy == [cat])[0][0]\n",
    "    category_list.append(index)\n",
    "#category_label = \n",
    "groundtruth = pd.DataFrame(rows_list)\n",
    "#result = pd.concat([dot, groundtruth], axis=1)\n",
    "\n",
    "print(\"Step 7\")\n",
    "categories = pd.DataFrame(category_list, columns=['category'])\n",
    "datasetst = pd.concat([dataset, categories], axis=1)\n",
    "\n",
    "print(\"Step 8\")\n",
    "dataset_numpy = datasetst.to_numpy()\n",
    "labels_numpy = groundtruth.to_numpy()\n",
    "categories_numpy = categories.to_numpy()\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(dataset_numpy, labels_numpy, test_size=0.05, random_state=0)\n",
    "\n",
    "print(\"Step 9\")\n",
    "x_train_df = pd.DataFrame(dataset_numpy, columns=['User','Latitude','Longitude', '0'])\n",
    "#x_test_df = pd.DataFrame(x_test, columns=['User','Latitude','Longitude', '0'])\n",
    "y_train_df = pd.DataFrame(labels_numpy)\n",
    "#y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "#Dataset with Users\n",
    "dataset1_df = pd.DataFrame(x_train_df['User'])\n",
    "\n",
    "index = 0\n",
    "for user in dataset1_df.iterrows():\n",
    "    user = user[0]\n",
    "    value = dataset1_df._get_value(user, 'User')\n",
    "    dataset1_df.xs(user)['User']=encoding_array.get(value)\n",
    "    #encoding.at[index,'user_id']=encoding_array.get(user)\n",
    "    index += 1\n",
    "    \n",
    "#Dataset with Poi's\n",
    "dataset2_df = pd.DataFrame(x_train_df[['Latitude']])\n",
    "dataset3_df = pd.DataFrame(x_train_df[['Longitude']])\n",
    "\n",
    "dataset4_df = pd.DataFrame(x_train_df[['0']])\n",
    "\n",
    "print(\"Step 10\")\n",
    "dataset1 = tf.convert_to_tensor(\n",
    "    dataset1_df, dtype=None, dtype_hint=None, name=None)\n",
    "dataset2 = tf.convert_to_tensor(\n",
    "    dataset2_df, dtype=None, dtype_hint=None, name=None)\n",
    "dataset3 = tf.convert_to_tensor(\n",
    "    dataset3_df, dtype=None, dtype_hint=None, name=None)\n",
    "dataset4 = tf.convert_to_tensor(\n",
    "    dataset4_df, dtype='int64', dtype_hint=None, name=None)\n",
    "labels = tf.convert_to_tensor(\n",
    "    y_train_df, dtype=None, dtype_hint=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e8971a26-2977-4d93-a1d7-08494713a95e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-4acc18e23fce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(x_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6ed9f6-1bb2-4361-b685-3b0b100d4e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{233919: 0, 190585: 1, 24779: 2, 30835: 3, 3884: 4, 18507: 5, 125878: 6, 79872: 7, 112400: 8, 16753: 9, 198380: 10, 3166: 11, 248459: 12, 166003: 13, 65942: 14, 85610: 15, 212753: 16, 11129: 17, 134643: 18, 98834: 19, 228886: 20, 9912: 21, 141345: 22, 36884: 23, 240687: 24, 259108: 25, 80758: 26, 132466: 27, 23885: 28, 81032: 29, 44648: 30, 24890: 31, 174210: 32, 178954: 33, 201854: 34, 75696: 35, 167913: 36, 93131: 37, 196441: 38, 3354: 39, 245399: 40, 139066: 41, 204627: 42, 110075: 43, 259848: 44, 99909: 45, 12829: 46, 162192: 47, 41675: 48, 43277: 49, 79388: 50, 3457: 51, 221413: 52, 145644: 53, 88502: 54, 87745: 55, 123798: 56, 201860: 57, 34500: 58, 64920: 59, 74284: 60, 215891: 61, 76403: 62, 81724: 63, 6085: 64, 234549: 65, 1643: 66, 150809: 67, 113696: 68, 57410: 69, 132704: 70, 183987: 71, 256254: 72, 26478: 73, 164480: 74, 5523: 75, 148702: 76, 230601: 77, 103351: 78, 129961: 79, 56432: 80, 152507: 81, 54512: 82, 186735: 83, 80978: 84, 50064: 85, 120094: 86, 86918: 87, 82541: 88, 90474: 89, 59516: 90, 147157: 91, 35520: 92, 71533: 93, 2285: 94, 218365: 95, 49545: 96, 118928: 97, 201375: 98, 235182: 99, 82500: 100, 45339: 101, 113559: 102, 94781: 103, 201553: 104, 8897: 105, 152655: 106, 206654: 107, 127917: 108, 263746: 109, 159853: 110, 260493: 111, 107391: 112, 21138: 113, 120005: 114, 203780: 115, 147159: 116, 145130: 117, 71644: 118, 204231: 119, 62448: 120, 55514: 121, 145375: 122, 177497: 123, 252286: 124, 221575: 125, 57807: 126, 44006: 127, 27000: 128, 77735: 129, 107652: 130, 135398: 131, 25108: 132, 17057: 133, 212378: 134, 154044: 135, 264156: 136, 179111: 137, 8177: 138, 173033: 139, 177396: 140, 94990: 141, 58348: 142, 105711: 143, 174501: 144, 183762: 145, 117325: 146, 59941: 147, 154742: 148, 93936: 149, 245304: 150, 77719: 151, 80726: 152, 41288: 153, 172837: 154, 33771: 155, 98995: 156, 139371: 157, 99022: 158, 164422: 159, 68936: 160, 45127: 161, 185773: 162, 51453: 163, 259202: 164, 136123: 165, 147188: 166, 128335: 167, 64445: 168, 108615: 169, 101245: 170, 136310: 171, 260950: 172, 111149: 173, 229099: 174, 88737: 175, 33517: 176, 60424: 177, 164326: 178, 39845: 179, 21838: 180, 234085: 181, 8438: 182, 105522: 183, 242489: 184, 22362: 185, 21467: 186, 108954: 187, 177406: 188, 228452: 189, 18810: 190, 27655: 191, 99356: 192, 43130: 193, 135886: 194, 156019: 195, 121137: 196, 151150: 197, 230978: 198, 158480: 199, 169980: 200, 255249: 201, 241033: 202, 11577: 203, 200394: 204, 132751: 205, 8549: 206, 157958: 207, 28380: 208, 248794: 209, 170532: 210, 165900: 211, 30460: 212, 156143: 213, 126485: 214, 94461: 215, 65917: 216, 190864: 217, 122874: 218, 33141: 219, 129700: 220, 123995: 221, 242296: 222, 162091: 223, 127863: 224, 263646: 225, 137446: 226, 126834: 227, 177804: 228, 106977: 229, 67810: 230, 81478: 231, 105251: 232, 7556: 233, 45084: 234, 79298: 235, 97890: 236, 90767: 237, 182759: 238, 184589: 239, 68628: 240, 136606: 241, 97179: 242, 38522: 243, 216973: 244, 154594: 245, 186166: 246, 52557: 247, 86712: 248, 7085: 249, 263515: 250, 146112: 251, 106354: 252, 99922: 253, 132671: 254, 166090: 255, 65426: 256, 10256: 257, 237577: 258, 162826: 259, 199287: 260, 70910: 261, 62394: 262, 196991: 263, 158848: 264, 52758: 265, 63229: 266, 202182: 267, 63132: 268, 48886: 269, 23384: 270, 11889: 271, 11871: 272, 187556: 273, 124019: 274, 63913: 275, 73847: 276, 14517: 277, 169299: 278, 185492: 279, 63844: 280, 2239: 281, 5637: 282, 12522: 283, 87421: 284, 64590: 285, 146748: 286, 108788: 287, 144224: 288, 186629: 289, 13749: 290, 112162: 291, 61517: 292, 242195: 293, 245581: 294, 108114: 295, 116516: 296, 90271: 297, 179008: 298, 104021: 299, 40457: 300, 232213: 301, 24356: 302, 37614: 303, 114966: 304, 212696: 305, 257620: 306, 18667: 307, 107583: 308, 165167: 309, 73856: 310, 43332: 311, 129477: 312, 222151: 313, 115426: 314, 130016: 315, 112834: 316, 5194: 317, 188647: 318, 11275: 319, 154818: 320, 156446: 321, 93716: 322, 52291: 323, 227755: 324, 184041: 325, 153637: 326, 133688: 327, 109036: 328, 135863: 329, 91557: 330, 16193: 331, 21034: 332, 92565: 333, 179400: 334, 177438: 335, 50244: 336, 42493: 337, 41046: 338, 137550: 339, 177298: 340, 204035: 341, 232351: 342, 95760: 343, 228459: 344, 98850: 345, 106897: 346, 75806: 347, 77803: 348, 230620: 349, 52179: 350, 215859: 351, 158620: 352, 186387: 353, 34437: 354, 48826: 355, 202689: 356, 212923: 357, 91070: 358, 69623: 359, 61518: 360, 235692: 361, 2736: 362, 55117: 363, 186138: 364, 42935: 365, 52753: 366, 115931: 367, 62201: 368, 264253: 369, 256570: 370, 2531: 371, 129151: 372, 35800: 373, 167915: 374, 3634: 375, 2277: 376, 34113: 377, 7978: 378, 149862: 379, 82431: 380, 210395: 381, 5721: 382, 128422: 383, 60939: 384, 71344: 385, 147716: 386, 154581: 387, 221751: 388, 108907: 389, 144045: 390, 8280: 391, 110192: 392, 202537: 393, 43904: 394, 50898: 395, 117140: 396, 108868: 397, 11260: 398, 79625: 399, 35730: 400, 181703: 401, 128294: 402, 31577: 403, 238249: 404, 165369: 405, 85176: 406, 145703: 407, 170303: 408, 136635: 409, 144233: 410, 51800: 411, 83874: 412, 12879: 413, 50540: 414, 56820: 415, 137469: 416, 40151: 417, 101575: 418, 220350: 419, 82642: 420, 172074: 421, 159960: 422, 1933: 423, 36136: 424, 237766: 425, 162415: 426, 181812: 427, 228598: 428, 38574: 429, 67129: 430, 165569: 431, 5499: 432, 78037: 433, 198695: 434, 68031: 435, 46486: 436, 156021: 437, 233937: 438, 166355: 439, 245426: 440, 45232: 441, 79809: 442, 154573: 443, 83051: 444, 74201: 445, 223849: 446, 186652: 447, 8006: 448, 18933: 449, 154779: 450, 134765: 451, 45045: 452, 95505: 453, 92002: 454, 150968: 455, 33709: 456, 120408: 457, 78734: 458, 111329: 459, 240675: 460, 154217: 461, 22784: 462, 39502: 463, 66601: 464, 58892: 465, 31340: 466, 14830: 467, 204240: 468, 137467: 469, 38850: 470, 33973: 471, 7881: 472, 222561: 473, 19358: 474, 209872: 475, 72303: 476, 139142: 477, 215977: 478, 133980: 479, 50986: 480, 28668: 481, 14415: 482, 264154: 483, 93921: 484, 215805: 485, 239411: 486, 44202: 487, 247880: 488, 138179: 489, 212997: 490, 145025: 491, 214702: 492, 255947: 493, 130224: 494, 190139: 495, 245599: 496, 28675: 497, 136: 498, 196561: 499, 218893: 500, 63039: 501, 89430: 502, 124151: 503, 83478: 504, 241933: 505, 215733: 506, 225333: 507, 35975: 508, 251280: 509, 26905: 510, 185307: 511, 8810: 512, 65492: 513, 201649: 514, 8018: 515, 71191: 516, 155807: 517, 12358: 518, 21257: 519, 169629: 520, 15637: 521, 143603: 522, 58460: 523, 210221: 524, 13961: 525, 21859: 526, 201974: 527, 232468: 528, 20543: 529, 97927: 530, 40999: 531, 80171: 532, 248293: 533, 1443: 534, 36500: 535, 221319: 536, 264987: 537, 164368: 538, 7126: 539, 209672: 540, 101006: 541, 113375: 542, 163836: 543, 108263: 544, 261618: 545, 21254: 546, 75325: 547, 138354: 548, 84095: 549, 113104: 550, 5323: 551, 193493: 552, 265153: 553, 49053: 554, 181305: 555, 140208: 556, 146708: 557, 19400: 558, 172709: 559, 5601: 560, 43029: 561, 49045: 562, 184941: 563, 62779: 564, 131639: 565, 222009: 566, 27418: 567, 13632: 568, 66280: 569, 116793: 570, 132504: 571, 105355: 572, 196084: 573, 236886: 574, 101164: 575, 168395: 576, 20112: 577, 70540: 578, 231394: 579, 160368: 580, 256932: 581, 245517: 582, 190913: 583, 122035: 584, 110050: 585, 148785: 586, 29817: 587, 1478: 588, 256634: 589, 224142: 590, 245518: 591, 94514: 592, 219110: 593, 23364: 594, 119734: 595, 206489: 596, 248406: 597, 23894: 598, 63521: 599, 177149: 600, 213347: 601, 5378: 602, 74246: 603, 260177: 604, 119804: 605, 171396: 606, 72242: 607, 157734: 608, 4686: 609, 121145: 610, 263940: 611, 240425: 612, 83388: 613, 75947: 614, 181308: 615, 40450: 616, 46490: 617, 29068: 618, 107671: 619, 252031: 620, 264101: 621, 83408: 622, 74297: 623, 207244: 624, 172683: 625, 31901: 626, 11352: 627, 201540: 628, 233927: 629, 204816: 630, 145579: 631, 141973: 632, 249191: 633, 31641: 634, 21820: 635, 125214: 636, 189543: 637, 95863: 638, 148856: 639, 127057: 640, 119145: 641, 117175: 642, 153771: 643, 212694: 644, 135961: 645, 199334: 646, 253034: 647, 261807: 648, 239581: 649, 91877: 650, 150430: 651, 243532: 652, 231773: 653, 163976: 654, 157745: 655, 127802: 656, 157914: 657, 137599: 658, 20743: 659, 131076: 660, 7325: 661, 160359: 662, 65641: 663, 201337: 664, 15292: 665, 260514: 666, 176871: 667, 230696: 668, 184257: 669, 7180: 670, 93073: 671, 255580: 672, 140840: 673, 170783: 674, 121687: 675, 259259: 676, 48586: 677, 6148: 678, 19529: 679, 134522: 680, 117653: 681, 49639: 682, 203256: 683, 57709: 684, 60281: 685, 40698: 686, 175787: 687, 233956: 688, 40062: 689, 186907: 690, 19298: 691, 35810: 692, 248450: 693, 222944: 694, 19619: 695, 213460: 696, 251026: 697, 46641: 698, 101085: 699, 124269: 700, 128224: 701, 206877: 702, 121308: 703, 120490: 704, 199875: 705, 248567: 706, 237417: 707, 241030: 708, 8473: 709, 166378: 710, 210204: 711, 95983: 712, 248699: 713, 76655: 714, 12123: 715, 45818: 716, 105582: 717, 158099: 718, 121378: 719, 142320: 720, 192539: 721, 159874: 722, 49344: 723, 244408: 724, 175270: 725, 211449: 726, 213261: 727, 103918: 728, 221946: 729, 91493: 730, 93981: 731, 53694: 732, 189407: 733, 140944: 734, 112008: 735, 186733: 736, 2241: 737, 241986: 738, 169898: 739, 248792: 740, 64311: 741, 5908: 742, 32975: 743, 86704: 744, 15774: 745, 202902: 746, 97397: 747, 245709: 748, 46963: 749, 266428: 750, 122110: 751, 54832: 752, 103310: 753, 249017: 754, 168782: 755, 235198: 756, 264745: 757, 41422: 758, 241971: 759, 159905: 760, 53959: 761, 8021: 762, 9914: 763, 254051: 764, 143621: 765, 198040: 766, 112710: 767, 259428: 768, 41284: 769, 133440: 770, 105257: 771, 189793: 772, 236270: 773, 236721: 774, 191353: 775, 85122: 776, 173013: 777, 70792: 778, 110280: 779, 134922: 780, 201725: 781, 105360: 782, 60028: 783, 117144: 784, 5613: 785, 100056: 786, 78563: 787, 220467: 788, 50826: 789, 31859: 790, 106442: 791, 113584: 792, 131475: 793, 53510: 794, 77878: 795, 91066: 796, 22142: 797, 76248: 798, 105453: 799, 138617: 800, 252541: 801, 91572: 802, 158127: 803, 114584: 804, 241203: 805, 191689: 806, 223771: 807, 127: 808, 127659: 809, 53557: 810, 83586: 811, 203662: 812, 102688: 813, 176990: 814, 242056: 815, 155802: 816, 209884: 817, 111566: 818, 215597: 819, 75416: 820, 226043: 821, 208008: 822, 33303: 823, 183779: 824, 132596: 825, 129494: 826, 175105: 827, 62643: 828, 65749: 829, 66516: 830, 192195: 831, 166461: 832, 77116: 833, 1516: 834, 134858: 835, 245574: 836, 252108: 837, 216031: 838, 224747: 839, 101882: 840, 263866: 841, 113848: 842, 111546: 843, 114867: 844, 3039: 845, 228568: 846, 181562: 847, 88749: 848, 131006: 849, 94040: 850, 121460: 851, 827: 852, 69118: 853, 88010: 854, 43183: 855, 206745: 856, 235473: 857, 112185: 858, 212193: 859, 81807: 860, 25419: 861, 173053: 862, 61002: 863, 203191: 864, 210628: 865, 90175: 866, 128041: 867, 35688: 868, 33276: 869, 257174: 870, 101379: 871, 93562: 872, 26242: 873, 688: 874, 84403: 875, 160748: 876, 69630: 877, 19686: 878, 112412: 879, 137151: 880, 163825: 881, 118430: 882, 56921: 883, 86575: 884, 147291: 885, 255467: 886, 11797: 887, 55090: 888, 110598: 889, 192069: 890, 152517: 891, 221925: 892, 78140: 893, 238296: 894, 71626: 895, 85739: 896, 245479: 897, 209749: 898, 204726: 899, 219514: 900, 61276: 901, 174314: 902, 186667: 903, 136114: 904, 252961: 905, 158201: 906, 139350: 907, 229866: 908, 172630: 909, 70246: 910, 232958: 911, 238645: 912, 97271: 913, 70784: 914, 101015: 915, 173522: 916, 242952: 917, 58199: 918, 132965: 919, 166119: 920, 70659: 921, 217480: 922, 69769: 923, 12546: 924, 237079: 925, 182152: 926, 213516: 927, 25159: 928, 6848: 929, 191615: 930, 5476: 931, 131001: 932, 75532: 933, 177252: 934, 198666: 935, 124010: 936, 27608: 937, 92192: 938, 113679: 939, 81554: 940, 220458: 941, 142251: 942, 66685: 943, 153200: 944, 95294: 945, 202177: 946, 220236: 947, 127253: 948, 37904: 949, 240347: 950, 125547: 951, 198352: 952, 110967: 953, 201607: 954, 219796: 955, 256751: 956, 78589: 957, 74088: 958, 24162: 959, 235247: 960, 153503: 961, 108846: 962}\n",
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 3.5\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n",
      "Step 8\n",
      "Step 9\n",
      "Step 10\n"
     ]
    }
   ],
   "source": [
    "encoding = pd.DataFrame(users, columns=['user_id'])\n",
    "#print(encoding)\n",
    "encoding_array = {}\n",
    "temp = 0\n",
    "for user in encoding.iterrows():\n",
    "    user = user[0]\n",
    "    value = encoding._get_value(user, 'user_id')\n",
    "    encoding_array[value] = temp\n",
    "    temp += 1\n",
    "\n",
    "print(encoding_array)    \n",
    "    \n",
    "# Iteration 1: User\n",
    "\n",
    "print(\"Step 1\")\n",
    "checkin_data = users.merge(pois, on='poi_id')\n",
    "df = checkin_data.set_index('user_id').poi_id.str.get_dummies(',')\n",
    "df = df.groupby('user_id').max()\n",
    "\n",
    "print(\"Step 2\")\n",
    "checkin_data_no_duplicates = checkin_data.copy()\n",
    "checkin_data_no_duplicates.drop_duplicates(subset =\"poi_id\", keep = 'first', inplace = True)\n",
    "checkin_data_no_duplicates = pd.DataFrame(checkin_data_no_duplicates, columns = ['poi_id', 'category'])\n",
    "\n",
    "#Extract categorical data\n",
    "print(\"Step 3\")\n",
    "categories = pd.DataFrame(checkin_data, columns=['category'])\n",
    "categories.drop_duplicates(subset =\"category\", keep = 'first', inplace = True)\n",
    "category_length = len(categories)\n",
    "categories_numpy = categories.to_numpy()\n",
    "\n",
    "\n",
    "#Extracting all of the users and the pois\n",
    "print(\"Step 3.5\")\n",
    "listofusers = pd.DataFrame(checkin_data, columns= ['user_id']).groupby('user_id').max().sample(frac=1)\n",
    "listofpois = pd.DataFrame(checkin_data, columns= ['poi_id', 'latitude', 'longitude']).groupby('poi_id').max().sample(frac=1)\n",
    "userarray = listofusers.index.to_numpy()\n",
    "poiarray = listofpois.index.to_numpy()\n",
    "userdataframe = pd.DataFrame(userarray, columns = ['Users'])\n",
    "poidataframe = pd.DataFrame(poiarray, columns = ['Poi'])\n",
    "dot = userdataframe.merge(poidataframe, how='cross')\n",
    "\n",
    "print(\"Step 4\")\n",
    "rows_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = dot.loc[i, \"Poi\"]\n",
    "    latitude = listofpois.loc[temp]['latitude']\n",
    "    longitude = listofpois.loc[temp]['longitude']\n",
    "    dict1 = {'latitude':latitude, 'longitude':longitude}\n",
    "    rows_list.append(dict1)\n",
    "    #latitude = poiarray[i]\n",
    "latlong = pd.DataFrame(rows_list)\n",
    "\n",
    "#Creating dataset\n",
    "print(\"Step 5\")\n",
    "userdot = pd.DataFrame(dot, columns= ['Users'])\n",
    "latlong['latitude'] = pd.to_numeric(latlong['latitude'])\n",
    "latlong['longitude'] = pd.to_numeric(latlong['longitude'])\n",
    "dataset = pd.concat([userdot, latlong], axis=1)\n",
    "\n",
    "#Extracting ground_truth from incidence matrix\n",
    "print(\"Step 6\")\n",
    "rows_list = []\n",
    "category_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    dict1 = {'ground_truth':float(temp)}\n",
    "    rows_list.append(dict1)\n",
    "    #Extract category from the list\n",
    "    category = checkin_data_no_duplicates.loc[checkin_data_no_duplicates['poi_id'] == dot.loc[i, \"Poi\"]]\n",
    "    cat = category['category']\n",
    "    index = np.where(categories_numpy == [cat])[0][0]\n",
    "    category_list.append(index)\n",
    "#category_label = \n",
    "groundtruth = pd.DataFrame(rows_list)\n",
    "#result = pd.concat([dot, groundtruth], axis=1)\n",
    "\n",
    "print(\"Step 7\")\n",
    "categories = pd.DataFrame(category_list, columns=['category'])\n",
    "datasetst = pd.concat([dataset, categories], axis=1)\n",
    "\n",
    "print(\"Step 8\")\n",
    "dataset_numpy = datasetst.to_numpy()\n",
    "labels_numpy = groundtruth.to_numpy()\n",
    "categories_numpy = categories.to_numpy()\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(dataset_numpy, labels_numpy, test_size=0.05, random_state=0)\n",
    "\n",
    "print(\"Step 9\")\n",
    "x_train_df = pd.DataFrame(dataset_numpy, columns=['User','Latitude','Longitude', '0'])\n",
    "#x_test_df = pd.DataFrame(x_test, columns=['User','Latitude','Longitude', '0'])\n",
    "y_train_df = pd.DataFrame(labels_numpy)\n",
    "#y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "#Dataset with Users\n",
    "dataset1_df = pd.DataFrame(x_train_df['User'])\n",
    "\n",
    "index = 0\n",
    "for user in dataset1_df.iterrows():\n",
    "    user = user[0]\n",
    "    value = dataset1_df._get_value(user, 'User')\n",
    "    dataset1_df.xs(user)['User']=encoding_array.get(value)\n",
    "    #encoding.at[index,'user_id']=encoding_array.get(user)\n",
    "    index += 1\n",
    "    \n",
    "#Dataset with Poi's\n",
    "dataset2_df = pd.DataFrame(x_train_df[['Latitude']])\n",
    "dataset3_df = pd.DataFrame(x_train_df[['Longitude']])\n",
    "\n",
    "dataset4_df = pd.DataFrame(x_train_df[['0']])\n",
    "\n",
    "print(\"Step 10\")\n",
    "dataset1 = tf.convert_to_tensor(\n",
    "    dataset1_df, dtype=None, dtype_hint=None, name=None)\n",
    "dataset2 = tf.convert_to_tensor(\n",
    "    dataset2_df, dtype=None, dtype_hint=None, name=None)\n",
    "dataset3 = tf.convert_to_tensor(\n",
    "    dataset3_df, dtype=None, dtype_hint=None, name=None)\n",
    "dataset4 = tf.convert_to_tensor(\n",
    "    dataset4_df, dtype='int64', dtype_hint=None, name=None)\n",
    "labels = tf.convert_to_tensor(\n",
    "    y_train_df, dtype=None, dtype_hint=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3307b-c2ef-472b-a0d6-a43d375bbae0",
   "metadata": {},
   "source": [
    "## dataset2_df[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f630d-5a85-4a59-a69f-0a3312601be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3359a2da-ae48-4aa4-a8ce-36e04bcd7fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "poi_latitude (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "poi_longitude (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 2)            0           poi_latitude[0][0]               \n",
      "                                                                 poi_longitude[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "category_input (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          384         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 128)       35712       category_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 128)       0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 1, 256)       0           embedding_14[0][0]               \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 256)       246528      user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 1, 1)         0           concatenate_15[0][0]             \n",
      "                                                                 embedding_15[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 282,624\n",
      "Trainable params: 282,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "963\n",
      "Epoch 1/25\n",
      "((<tf.Tensor 'IteratorGetNext:0' shape=(27, 1) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(27, 1) dtype=float64>, <tf.Tensor 'IteratorGetNext:2' shape=(27, 1) dtype=float64>, <tf.Tensor 'IteratorGetNext:3' shape=(27, 1) dtype=float64>), <tf.Tensor 'IteratorGetNext:4' shape=(27, 1) dtype=float64>)\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-71-87c85096a80c>:52 train_step\n        long_data = real_data[2]\n\n    IndexError: tuple index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-14bc87d8c04b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Train_data, [dataset.user_id, dataset.poi_id]. Label: ground_truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-71-87c85096a80c>:52 train_step\n        long_data = real_data[2]\n\n    IndexError: tuple index out of range\n"
     ]
    }
   ],
   "source": [
    "model = EmbModel(len(users), category_length)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "model.compile(\n",
    "    optimizer\n",
    ")\n",
    "\n",
    "#Train_data, [dataset.user_id, dataset.poi_id]. Label: ground_truth\n",
    "model.fit([dataset4, dataset2, dataset3, dataset1], labels, epochs = 25, batch_size=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b571a2d1-cc6c-4d08-ac18-3188d50af7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.EmbModel object at 0x0000028064F13940>, because it is not built.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model <__main__.EmbModel object at 0x0000028064F13940> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling `.fit()` or `.predict()`. To manually set the shapes, call `model.build(input_shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-2b86d13ff0cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\lasse\\Desktop\\RecommenderDL\\models\\model2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1976\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m-> 1978\u001b[1;33m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[0;32m   1979\u001b[0m                     signatures, options)\n\u001b[0;32m   1980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    131\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[0;32m    132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0m\u001b[0;32m    134\u001b[0m                           signatures, options)\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msave_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_skip_serialization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0msaving_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_model_input_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py\u001b[0m in \u001b[0;36mraise_model_input_error\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_model_input_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m   raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m       \u001b[1;34m'Model {} cannot be saved because the input shapes have not been '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m       \u001b[1;34m'set. Usually, input shapes are automatically determined from calling'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Model <__main__.EmbModel object at 0x0000028064F13940> cannot be saved because the input shapes have not been set. Usually, input shapes are automatically determined from calling `.fit()` or `.predict()`. To manually set the shapes, call `model.build(input_shape)`."
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\models\\model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45374292-a588-4870-bc1d-0ed688a197de",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer has never been called and thus has no defined input shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b37dfe69eafc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36minput_shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2124\u001b[0m     \"\"\"\n\u001b[0;32m   2125\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2126\u001b[1;33m       raise AttributeError('The layer has never been called '\n\u001b[0m\u001b[0;32m   2127\u001b[0m                            'and thus has no defined input shape.')\n\u001b[0;32m   2128\u001b[0m     all_input_shapes = set(\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer has never been called and thus has no defined input shape."
     ]
    }
   ],
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4f5a3-5d65-4ec6-a23b-8e3870bda468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
