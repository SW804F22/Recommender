{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811cab43-8f72-4eaa-a9f1-e2bdd83ccb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Normalizer , scale\n",
    "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import plot_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c1cac6-46be-4e4f-b323-f85f05d8a1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: DtypeWarning: Columns (0,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\lasse\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: DtypeWarning: Columns (1,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "checkin_cols = ['user_id', 'poi_id', 'timestamp', 'timezone']\n",
    "checkins = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\TIST2015_Checkins.csv', sep=',', names=checkin_cols, encoding='latin-1')\n",
    "\n",
    "venue_cols = ['poi_id', 'latitude', 'longitude', 'category', 'country_code']\n",
    "pois = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\TIST2015_POIs.csv', sep=',', names=venue_cols, encoding='latin-1')\n",
    "\n",
    "databasepoi_cols = ['poi_id']\n",
    "databasepoi = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\databasePOI.csv', sep=',', names=databasepoi_cols, encoding='latin-1')[1:]\n",
    "\n",
    "#Getting all the pois from the database (Der skal være cirka 91000?)\n",
    "pois_subset = pois.merge(databasepoi, on='poi_id')\n",
    "\n",
    "#Getting checkins from subset (Der skal være cirka 800000)\n",
    "temp = checkins.copy()\n",
    "checkins_subset = temp.merge(pois_subset, on='poi_id')\n",
    "\n",
    "#Getting users from subset (Der skal cirka være 172000)\n",
    "users_subset = checkins_subset.copy()\n",
    "users_subset.drop_duplicates(subset=\"user_id\", keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606b5de-396a-4542-bcf9-960f5646e9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f2a1e18-a90c-41b0-86e0-fd6ce6f0ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition 1\n",
    "checkin_data = users_subset[:28741]\n",
    "df = checkin_data.set_index('user_id').poi_id.str.get_dummies(',')\n",
    "df = df.groupby('user_id').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8a1fa86-3365-41a0-84d0-96b266c90989",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_data_no_duplicates = checkin_data.copy()\n",
    "checkin_data_no_duplicates.drop_duplicates(subset =\"poi_id\",\n",
    "                     keep = 'first', inplace = True)\n",
    "checkin_data_no_duplicates = pd.DataFrame(checkin_data_no_duplicates, columns = ['poi_id', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23390853-2015-4fa3-a78e-6e6cdd7c1883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract categorical data\n"
     ]
    }
   ],
   "source": [
    "#Extract categorical data\n",
    "print(\"Extract categorical data\")\n",
    "categories = pd.DataFrame(checkin_data, columns=['category'])\n",
    "categories.drop_duplicates(subset =\"category\",\n",
    "                           keep = 'first', inplace = True)\n",
    "category_length = len(categories)\n",
    "categories_numpy = categories.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2361c0e-332f-4c9d-aa43-a0c1a57583bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.82 GiB for an array with shape (378782032,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-38bb12dbf8bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0muserdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Users'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpoidataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoiarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Poi'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muserdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoidataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cross'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9189\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9191\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m   9192\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9193\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     )\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         llabels, rlabels = _items_overlap_with_suffix(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    997\u001b[0m                     \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m                 \u001b[0mjoin_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_indexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype_to_subclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m             \u001b[0mdisallow_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\numeric.py\u001b[0m in \u001b[0;36m_ensure_array\u001b[1;34m(cls, data, dtype, copy)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_dtype_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_safe_casting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.82 GiB for an array with shape (378782032,) and data type int64"
     ]
    }
   ],
   "source": [
    "#Extracting all of the users and the pois\n",
    "listofusers = pd.DataFrame(checkin_data, columns= ['user_id']).groupby('user_id').max().sample(frac=1)\n",
    "listofpois = pd.DataFrame(checkin_data, columns= ['poi_id', 'latitude', 'longitude']).groupby('poi_id').max().sample(frac=1)\n",
    "userarray = listofusers.index.to_numpy()\n",
    "poiarray = listofpois.index.to_numpy()\n",
    "userdataframe = pd.DataFrame(userarray, columns = ['Users'])\n",
    "poidataframe = pd.DataFrame(poiarray, columns = ['Poi'])\n",
    "dot = userdataframe.merge(poidataframe, how='cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef1701-88cf-48bd-85ab-731db0325586",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = dot.loc[i, \"Poi\"]\n",
    "    latitude = listofpois.loc[temp]['latitude']\n",
    "    longitude = listofpois.loc[temp]['longitude']\n",
    "    dict1 = {'latitude':latitude, 'longitude':longitude}\n",
    "    rows_list.append(dict1)\n",
    "    #latitude = poiarray[i]\n",
    "latlong = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c51ca9-d4e7-4aa0-961d-536a9089fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataset\n",
    "userdot = pd.DataFrame(dot, columns= ['Users'])\n",
    "latlong['latitude'] = pd.to_numeric(latlong['latitude'])\n",
    "latlong['longitude'] = pd.to_numeric(latlong['longitude'])\n",
    "dataset = pd.concat([userdot, latlong], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa2028-9cbc-4f0c-8b46-97a528904c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting ground_truth from incidence matrix\n",
    "rows_list = []\n",
    "category_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    dict1 = {'ground_truth':float(temp)}\n",
    "    rows_list.append(dict1)\n",
    "    #Extract category from the list\n",
    "    category = checkin_data_no_duplicates.loc[checkin_data_no_duplicates['poi_id'] == dot.loc[i, \"Poi\"]]\n",
    "    cat = category['category']\n",
    "    index = np.where(categories_numpy == [cat])[0][0]\n",
    "    category_list.append(index)\n",
    "#category_label = \n",
    "groundtruth = pd.DataFrame(rows_list)\n",
    "#result = pd.concat([dot, groundtruth], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8459d9-e203-47c4-81c5-71d2a0785e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Normalizer , scale\n",
    "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "\n",
    "checkin_cols = ['user_id', 'poi_id', 'timestamp', 'timezone']\n",
    "checkins = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\TIST2015_Checkins.csv', sep=',', names=checkin_cols, encoding='latin-1')\n",
    "\n",
    "venue_cols = ['poi_id', 'latitude', 'longitude', 'category', 'country_code']\n",
    "pois = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\TIST2015_POIs.csv', sep=',', names=venue_cols, encoding='latin-1')\n",
    "\n",
    "databasepoi_cols = ['poi_id']\n",
    "databasepoi = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\databasePOI.csv', sep=',', names=databasepoi_cols, encoding='latin-1')[1:]\n",
    "\n",
    "#Getting all the pois from the database (Der skal være cirka 91000?)\n",
    "pois_subset = pois.merge(databasepoi, on='poi_id')\n",
    "\n",
    "#Getting checkins from subset (Der skal være cirka 800000)\n",
    "temp = checkins.copy()\n",
    "checkins_subset = temp.merge(pois_subset, on='poi_id')\n",
    "\n",
    "#Getting users from subset (Der skal cirka være 172000)\n",
    "users_subset = checkins_subset.copy()\n",
    "users_subset.drop_duplicates(subset=\"user_id\", keep = 'first', inplace = True)\n",
    "\n",
    "#Partition 1\n",
    "print(\"Partition 1\")\n",
    "checkin_data = users[:57482]\n",
    "df = checkin_data.set_index('user_id').poi_id.str.get_dummies(',')\n",
    "df = df.groupby('user_id').max()\n",
    "\n",
    "checkin_data_no_duplicates = checkin_data.copy()\n",
    "checkin_data_no_duplicates.drop_duplicates(subset =\"poi_id\",\n",
    "                     keep = 'first', inplace = True)\n",
    "checkin_data_no_duplicates = pd.DataFrame(checkin_data_no_duplicates, columns = ['poi_id', 'category'])\n",
    "\n",
    "#Extract categorical data\n",
    "print(\"Extract categorical data\")\n",
    "categories = pd.DataFrame(checkin_data, columns=['category'])\n",
    "categories.drop_duplicates(subset =\"category\",\n",
    "                           keep = 'first', inplace = True)\n",
    "category_length = len(categories)\n",
    "categories_numpy = categories.to_numpy()\n",
    "\n",
    "#Extracting all of the users and the pois\n",
    "print(\"Extracting all of the users and the pois\")\n",
    "listofusers = pd.DataFrame(checkin_data, columns= ['user_id']).groupby('user_id').max().sample(frac=1)\n",
    "listofpois = pd.DataFrame(checkin_data, columns= ['poi_id', 'latitude', 'longitude']).groupby('poi_id').max().sample(frac=1)\n",
    "userarray = listofusers.index.to_numpy()\n",
    "poiarray = listofpois.index.to_numpy()\n",
    "userdataframe = pd.DataFrame(userarray, columns = ['Users'])\n",
    "poidataframe = pd.DataFrame(poiarray, columns = ['Poi'])\n",
    "dot = userdataframe.merge(poidataframe, how='cross')\n",
    "\n",
    "#LatLong\n",
    "print(\"LatLong\")\n",
    "rows_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = dot.loc[i, \"Poi\"]\n",
    "    latitude = listofpois.loc[temp]['latitude']\n",
    "    longitude = listofpois.loc[temp]['longitude']\n",
    "    dict1 = {'latitude':latitude, 'longitude':longitude}\n",
    "    rows_list.append(dict1)\n",
    "    #latitude = poiarray[i]\n",
    "latlong = pd.DataFrame(rows_list)\n",
    "\n",
    "#Creating dataset\n",
    "print(\"Creating dataset\")\n",
    "userdot = pd.DataFrame(dot, columns= ['Users'])\n",
    "latlong['latitude'] = pd.to_numeric(latlong['latitude'])\n",
    "latlong['longitude'] = pd.to_numeric(latlong['longitude'])\n",
    "dataset = pd.concat([userdot, latlong], axis=1)\n",
    "\n",
    "#Extracting ground_truth from incidence matrix\n",
    "print(\"Extracting ground_truth from incidence matrix\")\n",
    "rows_list = []\n",
    "category_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    dict1 = {'ground_truth':float(temp)}\n",
    "    rows_list.append(dict1)\n",
    "    #Extract category from the list\n",
    "    category = checkin_data_no_duplicates.loc[checkin_data_no_duplicates['poi_id'] == dot.loc[i, \"Poi\"]]\n",
    "    cat = category['category']\n",
    "    index = np.where(categories_numpy == [cat])[0][0]\n",
    "    category_list.append(index)\n",
    "#category_label = \n",
    "groundtruth = pd.DataFrame(rows_list)\n",
    "#result = pd.concat([dot, groundtruth], axis=1)\n",
    "\n",
    "categories = pd.DataFrame(category_list, columns=['category'])\n",
    "datasetst = pd.concat([dataset, categories], axis=1)\n",
    "\n",
    "dataset_numpy = datasetst.to_numpy()\n",
    "labels_numpy = groundtruth.to_numpy()\n",
    "categories_numpy = categories.to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_numpy, labels_numpy, test_size=0.05, random_state=0)\n",
    "\n",
    "x_train_df = pd.DataFrame(x_train, columns=['User','Latitude','Longitude', '0'])\n",
    "x_test_df = pd.DataFrame(x_test, columns=['User','Latitude','Longitude', '0'])\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "#Dataset with Users\n",
    "dataset1_df = pd.DataFrame(x_train_df['User'])\n",
    "\n",
    "#Dataset with Poi's\n",
    "dataset2_df = pd.DataFrame(x_train_df[['Latitude', 'Longitude']])\n",
    "\n",
    "dataset3_df = pd.DataFrame(x_train_df[['0']])\n",
    "\n",
    "dataset1_df.to_csv(sep=',', index=['User'])\n",
    "dataset2_df.to_csv(sep=',', index=['Latitude', 'Longitude'])\n",
    "dataset3_df.to_csv(sep=',', index=['0'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
