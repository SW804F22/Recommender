{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9234f3-24ae-497c-b559-82d4b1b5778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eee30f07-e6e4-4011-9e3f-c4d33c58129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbModel(tf.keras.Model):\n",
    "    def __init__(self, useridlength, category_length):\n",
    "        super(EmbModel, self).__init__()\n",
    "        self.d_steps = 1\n",
    "        self.useridlength = useridlength\n",
    "        self.category_length = category_length\n",
    "        self.model = self.init_model()\n",
    "        print(self.useridlength)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return\n",
    "    \n",
    "    def init_model(self):\n",
    "        poi_latitude_input = keras.layers.Input(shape=(1,), name='poi_latitude')\n",
    "        poi_longitude_input = keras.layers.Input(shape=(1,), name='poi_longitude')\n",
    "        poi_concat_input = tf.keras.layers.Concatenate(axis=-1)([poi_latitude_input, poi_longitude_input])\n",
    "        #input_length:  #This is the length of input sequences, as you would define for any input layer of a Keras model. \n",
    "                        #For example, if all of your input documents are comprised of 1000 words, this would be 1000\n",
    "        #input_dim: \n",
    "                        #This is the size of the vocabulary in the text data. \n",
    "                        #For example, if your data is integer encoded to values between 0-10, then the size of the vocabulary would be 11 words.\n",
    "        poi_dense = keras.layers.Dense(128)(poi_concat_input)\n",
    "        poi_reshape = keras.layers.Reshape((1, 128))(poi_dense)\n",
    "        \n",
    "        category_input = keras.layers.Input(shape=(1), name='category_input')\n",
    "        category_emb = keras.layers.Embedding(self.category_length, 128)(category_input)    \n",
    "        category_concat = tf.keras.layers.Concatenate(axis=-1)([category_emb, poi_reshape])\n",
    "    \n",
    "        user_input = keras.layers.Input(shape=(1,), name='user_id')\n",
    "        user_emb = keras.layers.Embedding(self.useridlength, 256)(user_input)\n",
    "        #user_reshape = layers.Reshape((1, 256))(user_emb)\n",
    "                                    \n",
    "        dot = keras.layers.Dot(axes=(2))([category_concat, user_emb])\n",
    "            \n",
    "        model = Model([category_input, poi_latitude_input, poi_longitude_input, user_input], dot)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    def compile_model(self, optimizer):\n",
    "        super(EmbModel, self).compile(run_eagerly=True)\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        if len(data) == 3:\n",
    "            real_data, labels, sample_weight = data\n",
    "        else:\n",
    "            sample_weight = None\n",
    "            real_data, labels = data\n",
    "        cat_data = real_data[0]\n",
    "        lat_data = real_data[1]\n",
    "        long_data = real_data[2]\n",
    "        user_data = real_data[3]\n",
    "\n",
    "        for i in range(self.d_steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                \n",
    "                #print(latlong_data[0])\n",
    "                #print(latlong_data[1])\n",
    "                #print(user_data)\n",
    "                \n",
    "                dotproduct = self.model(real_data)\n",
    "                print(dotproduct)\n",
    "                #print(dotproduct)\n",
    "                # Loss function = ||S-GroundTruth|| \n",
    "                loss = tf.math.abs(tf.subtract(tf.cast(dotproduct, tf.float64), labels))\n",
    "                #print(loss)\n",
    "            d_gradient = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(d_gradient, self.model.trainable_variables))\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.out_units)\n",
    "    \n",
    "    def predict_step(self, data):\n",
    "        sample_weight = None\n",
    "        cat_data = real_data[0]\n",
    "        lat_data = real_data[1]\n",
    "        long_data = real_data[2]\n",
    "        user_data = real_data[3]\n",
    "        return self.model([cat_data, lat_data, long_data, user_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72be7f6-2461-410c-befb-c6906ed0f1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330a28c0-9db5-4018-90dc-b6a9d44733cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(ground_truth, lst):\n",
    "    result = []\n",
    "    for category in lst:\n",
    "        oh_encoding = np.zeros(len(ground_truth))\n",
    "        if category in ground_truth:\n",
    "            print(category)\n",
    "            index = np.where(ground_truth == category)[0][0]\n",
    "            \n",
    "            #Get index og category, and insert 1 into the vector.\n",
    "            result.append(index)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9c1cac5-27ff-487f-babc-2168565c8d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkins\n",
      "Loading POIs\n",
      "Checkins:  10473\n",
      "Users:  963\n",
      "Gotten:  9510\n",
      "Unique categories in checkins_rest:  279\n",
      "Total categories:  279\n",
      "Overview:\n",
      "963\n",
      "279\n",
      "9228\n",
      "{233919: 0, 190585: 1, 24779: 2, 30835: 3, 3884: 4, 18507: 5, 125878: 6, 79872: 7, 112400: 8, 16753: 9, 198380: 10, 3166: 11, 248459: 12, 166003: 13, 65942: 14, 85610: 15, 212753: 16, 11129: 17, 134643: 18, 98834: 19, 228886: 20, 9912: 21, 141345: 22, 36884: 23, 240687: 24, 259108: 25, 80758: 26, 132466: 27, 23885: 28, 81032: 29, 44648: 30, 24890: 31, 174210: 32, 178954: 33, 201854: 34, 75696: 35, 167913: 36, 93131: 37, 196441: 38, 3354: 39, 245399: 40, 139066: 41, 204627: 42, 110075: 43, 259848: 44, 99909: 45, 12829: 46, 162192: 47, 41675: 48, 43277: 49, 79388: 50, 3457: 51, 221413: 52, 145644: 53, 88502: 54, 87745: 55, 123798: 56, 201860: 57, 34500: 58, 64920: 59, 74284: 60, 215891: 61, 76403: 62, 81724: 63, 6085: 64, 234549: 65, 1643: 66, 150809: 67, 113696: 68, 57410: 69, 132704: 70, 183987: 71, 256254: 72, 26478: 73, 164480: 74, 5523: 75, 148702: 76, 230601: 77, 103351: 78, 129961: 79, 56432: 80, 152507: 81, 54512: 82, 186735: 83, 80978: 84, 50064: 85, 120094: 86, 86918: 87, 82541: 88, 90474: 89, 59516: 90, 147157: 91, 35520: 92, 71533: 93, 2285: 94, 218365: 95, 49545: 96, 118928: 97, 201375: 98, 235182: 99, 82500: 100, 45339: 101, 113559: 102, 94781: 103, 201553: 104, 8897: 105, 152655: 106, 206654: 107, 127917: 108, 263746: 109, 159853: 110, 260493: 111, 107391: 112, 21138: 113, 120005: 114, 203780: 115, 147159: 116, 145130: 117, 71644: 118, 204231: 119, 62448: 120, 55514: 121, 145375: 122, 177497: 123, 252286: 124, 221575: 125, 57807: 126, 44006: 127, 27000: 128, 77735: 129, 107652: 130, 135398: 131, 25108: 132, 17057: 133, 212378: 134, 154044: 135, 264156: 136, 179111: 137, 8177: 138, 173033: 139, 177396: 140, 94990: 141, 58348: 142, 105711: 143, 174501: 144, 183762: 145, 117325: 146, 59941: 147, 154742: 148, 93936: 149, 245304: 150, 77719: 151, 80726: 152, 41288: 153, 172837: 154, 33771: 155, 98995: 156, 139371: 157, 99022: 158, 164422: 159, 68936: 160, 45127: 161, 185773: 162, 51453: 163, 259202: 164, 136123: 165, 147188: 166, 128335: 167, 64445: 168, 108615: 169, 101245: 170, 136310: 171, 260950: 172, 111149: 173, 229099: 174, 88737: 175, 33517: 176, 60424: 177, 164326: 178, 39845: 179, 21838: 180, 234085: 181, 8438: 182, 105522: 183, 242489: 184, 22362: 185, 21467: 186, 108954: 187, 177406: 188, 228452: 189, 18810: 190, 27655: 191, 99356: 192, 43130: 193, 135886: 194, 156019: 195, 121137: 196, 151150: 197, 230978: 198, 158480: 199, 169980: 200, 255249: 201, 241033: 202, 11577: 203, 200394: 204, 132751: 205, 8549: 206, 157958: 207, 28380: 208, 248794: 209, 170532: 210, 165900: 211, 30460: 212, 156143: 213, 126485: 214, 94461: 215, 65917: 216, 190864: 217, 122874: 218, 33141: 219, 129700: 220, 123995: 221, 242296: 222, 162091: 223, 127863: 224, 263646: 225, 137446: 226, 126834: 227, 177804: 228, 106977: 229, 67810: 230, 81478: 231, 105251: 232, 7556: 233, 45084: 234, 79298: 235, 97890: 236, 90767: 237, 182759: 238, 184589: 239, 68628: 240, 136606: 241, 97179: 242, 38522: 243, 216973: 244, 154594: 245, 186166: 246, 52557: 247, 86712: 248, 7085: 249, 263515: 250, 146112: 251, 106354: 252, 99922: 253, 132671: 254, 166090: 255, 65426: 256, 10256: 257, 237577: 258, 162826: 259, 199287: 260, 70910: 261, 62394: 262, 196991: 263, 158848: 264, 52758: 265, 63229: 266, 202182: 267, 63132: 268, 48886: 269, 23384: 270, 11889: 271, 11871: 272, 187556: 273, 124019: 274, 63913: 275, 73847: 276, 14517: 277, 169299: 278, 185492: 279, 63844: 280, 2239: 281, 5637: 282, 12522: 283, 87421: 284, 64590: 285, 146748: 286, 108788: 287, 144224: 288, 186629: 289, 13749: 290, 112162: 291, 61517: 292, 242195: 293, 245581: 294, 108114: 295, 116516: 296, 90271: 297, 179008: 298, 104021: 299, 40457: 300, 232213: 301, 24356: 302, 37614: 303, 114966: 304, 212696: 305, 257620: 306, 18667: 307, 107583: 308, 165167: 309, 73856: 310, 43332: 311, 129477: 312, 222151: 313, 115426: 314, 130016: 315, 112834: 316, 5194: 317, 188647: 318, 11275: 319, 154818: 320, 156446: 321, 93716: 322, 52291: 323, 227755: 324, 184041: 325, 153637: 326, 133688: 327, 109036: 328, 135863: 329, 91557: 330, 16193: 331, 21034: 332, 92565: 333, 179400: 334, 177438: 335, 50244: 336, 42493: 337, 41046: 338, 137550: 339, 177298: 340, 204035: 341, 232351: 342, 95760: 343, 228459: 344, 98850: 345, 106897: 346, 75806: 347, 77803: 348, 230620: 349, 52179: 350, 215859: 351, 158620: 352, 186387: 353, 34437: 354, 48826: 355, 202689: 356, 212923: 357, 91070: 358, 69623: 359, 61518: 360, 235692: 361, 2736: 362, 55117: 363, 186138: 364, 42935: 365, 52753: 366, 115931: 367, 62201: 368, 264253: 369, 256570: 370, 2531: 371, 129151: 372, 35800: 373, 167915: 374, 3634: 375, 2277: 376, 34113: 377, 7978: 378, 149862: 379, 82431: 380, 210395: 381, 5721: 382, 128422: 383, 60939: 384, 71344: 385, 147716: 386, 154581: 387, 221751: 388, 108907: 389, 144045: 390, 8280: 391, 110192: 392, 202537: 393, 43904: 394, 50898: 395, 117140: 396, 108868: 397, 11260: 398, 79625: 399, 35730: 400, 181703: 401, 128294: 402, 31577: 403, 238249: 404, 165369: 405, 85176: 406, 145703: 407, 170303: 408, 136635: 409, 144233: 410, 51800: 411, 83874: 412, 12879: 413, 50540: 414, 56820: 415, 137469: 416, 40151: 417, 101575: 418, 220350: 419, 82642: 420, 172074: 421, 159960: 422, 1933: 423, 36136: 424, 237766: 425, 162415: 426, 181812: 427, 228598: 428, 38574: 429, 67129: 430, 165569: 431, 5499: 432, 78037: 433, 198695: 434, 68031: 435, 46486: 436, 156021: 437, 233937: 438, 166355: 439, 245426: 440, 45232: 441, 79809: 442, 154573: 443, 83051: 444, 74201: 445, 223849: 446, 186652: 447, 8006: 448, 18933: 449, 154779: 450, 134765: 451, 45045: 452, 95505: 453, 92002: 454, 150968: 455, 33709: 456, 120408: 457, 78734: 458, 111329: 459, 240675: 460, 154217: 461, 22784: 462, 39502: 463, 66601: 464, 58892: 465, 31340: 466, 14830: 467, 204240: 468, 137467: 469, 38850: 470, 33973: 471, 7881: 472, 222561: 473, 19358: 474, 209872: 475, 72303: 476, 139142: 477, 215977: 478, 133980: 479, 50986: 480, 28668: 481, 14415: 482, 264154: 483, 93921: 484, 215805: 485, 239411: 486, 44202: 487, 247880: 488, 138179: 489, 212997: 490, 145025: 491, 214702: 492, 255947: 493, 130224: 494, 190139: 495, 245599: 496, 28675: 497, 136: 498, 196561: 499, 218893: 500, 63039: 501, 89430: 502, 124151: 503, 83478: 504, 241933: 505, 215733: 506, 225333: 507, 35975: 508, 251280: 509, 26905: 510, 185307: 511, 8810: 512, 65492: 513, 201649: 514, 8018: 515, 71191: 516, 155807: 517, 12358: 518, 21257: 519, 169629: 520, 15637: 521, 143603: 522, 58460: 523, 210221: 524, 13961: 525, 21859: 526, 201974: 527, 232468: 528, 20543: 529, 97927: 530, 40999: 531, 80171: 532, 248293: 533, 1443: 534, 36500: 535, 221319: 536, 264987: 537, 164368: 538, 7126: 539, 209672: 540, 101006: 541, 113375: 542, 163836: 543, 108263: 544, 261618: 545, 21254: 546, 75325: 547, 138354: 548, 84095: 549, 113104: 550, 5323: 551, 193493: 552, 265153: 553, 49053: 554, 181305: 555, 140208: 556, 146708: 557, 19400: 558, 172709: 559, 5601: 560, 43029: 561, 49045: 562, 184941: 563, 62779: 564, 131639: 565, 222009: 566, 27418: 567, 13632: 568, 66280: 569, 116793: 570, 132504: 571, 105355: 572, 196084: 573, 236886: 574, 101164: 575, 168395: 576, 20112: 577, 70540: 578, 231394: 579, 160368: 580, 256932: 581, 245517: 582, 190913: 583, 122035: 584, 110050: 585, 148785: 586, 29817: 587, 1478: 588, 256634: 589, 224142: 590, 245518: 591, 94514: 592, 219110: 593, 23364: 594, 119734: 595, 206489: 596, 248406: 597, 23894: 598, 63521: 599, 177149: 600, 213347: 601, 5378: 602, 74246: 603, 260177: 604, 119804: 605, 171396: 606, 72242: 607, 157734: 608, 4686: 609, 121145: 610, 263940: 611, 240425: 612, 83388: 613, 75947: 614, 181308: 615, 40450: 616, 46490: 617, 29068: 618, 107671: 619, 252031: 620, 264101: 621, 83408: 622, 74297: 623, 207244: 624, 172683: 625, 31901: 626, 11352: 627, 201540: 628, 233927: 629, 204816: 630, 145579: 631, 141973: 632, 249191: 633, 31641: 634, 21820: 635, 125214: 636, 189543: 637, 95863: 638, 148856: 639, 127057: 640, 119145: 641, 117175: 642, 153771: 643, 212694: 644, 135961: 645, 199334: 646, 253034: 647, 261807: 648, 239581: 649, 91877: 650, 150430: 651, 243532: 652, 231773: 653, 163976: 654, 157745: 655, 127802: 656, 157914: 657, 137599: 658, 20743: 659, 131076: 660, 7325: 661, 160359: 662, 65641: 663, 201337: 664, 15292: 665, 260514: 666, 176871: 667, 230696: 668, 184257: 669, 7180: 670, 93073: 671, 255580: 672, 140840: 673, 170783: 674, 121687: 675, 259259: 676, 48586: 677, 6148: 678, 19529: 679, 134522: 680, 117653: 681, 49639: 682, 203256: 683, 57709: 684, 60281: 685, 40698: 686, 175787: 687, 233956: 688, 40062: 689, 186907: 690, 19298: 691, 35810: 692, 248450: 693, 222944: 694, 19619: 695, 213460: 696, 251026: 697, 46641: 698, 101085: 699, 124269: 700, 128224: 701, 206877: 702, 121308: 703, 120490: 704, 199875: 705, 248567: 706, 237417: 707, 241030: 708, 8473: 709, 166378: 710, 210204: 711, 95983: 712, 248699: 713, 76655: 714, 12123: 715, 45818: 716, 105582: 717, 158099: 718, 121378: 719, 142320: 720, 192539: 721, 159874: 722, 49344: 723, 244408: 724, 175270: 725, 211449: 726, 213261: 727, 103918: 728, 221946: 729, 91493: 730, 93981: 731, 53694: 732, 189407: 733, 140944: 734, 112008: 735, 186733: 736, 2241: 737, 241986: 738, 169898: 739, 248792: 740, 64311: 741, 5908: 742, 32975: 743, 86704: 744, 15774: 745, 202902: 746, 97397: 747, 245709: 748, 46963: 749, 266428: 750, 122110: 751, 54832: 752, 103310: 753, 249017: 754, 168782: 755, 235198: 756, 264745: 757, 41422: 758, 241971: 759, 159905: 760, 53959: 761, 8021: 762, 9914: 763, 254051: 764, 143621: 765, 198040: 766, 112710: 767, 259428: 768, 41284: 769, 133440: 770, 105257: 771, 189793: 772, 236270: 773, 236721: 774, 191353: 775, 85122: 776, 173013: 777, 70792: 778, 110280: 779, 134922: 780, 201725: 781, 105360: 782, 60028: 783, 117144: 784, 5613: 785, 100056: 786, 78563: 787, 220467: 788, 50826: 789, 31859: 790, 106442: 791, 113584: 792, 131475: 793, 53510: 794, 77878: 795, 91066: 796, 22142: 797, 76248: 798, 105453: 799, 138617: 800, 252541: 801, 91572: 802, 158127: 803, 114584: 804, 241203: 805, 191689: 806, 223771: 807, 127: 808, 127659: 809, 53557: 810, 83586: 811, 203662: 812, 102688: 813, 176990: 814, 242056: 815, 155802: 816, 209884: 817, 111566: 818, 215597: 819, 75416: 820, 226043: 821, 208008: 822, 33303: 823, 183779: 824, 132596: 825, 129494: 826, 175105: 827, 62643: 828, 65749: 829, 66516: 830, 192195: 831, 166461: 832, 77116: 833, 1516: 834, 134858: 835, 245574: 836, 252108: 837, 216031: 838, 224747: 839, 101882: 840, 263866: 841, 113848: 842, 111546: 843, 114867: 844, 3039: 845, 228568: 846, 181562: 847, 88749: 848, 131006: 849, 94040: 850, 121460: 851, 827: 852, 69118: 853, 88010: 854, 43183: 855, 206745: 856, 235473: 857, 112185: 858, 212193: 859, 81807: 860, 25419: 861, 173053: 862, 61002: 863, 203191: 864, 210628: 865, 90175: 866, 128041: 867, 35688: 868, 33276: 869, 257174: 870, 101379: 871, 93562: 872, 26242: 873, 688: 874, 84403: 875, 160748: 876, 69630: 877, 19686: 878, 112412: 879, 137151: 880, 163825: 881, 118430: 882, 56921: 883, 86575: 884, 147291: 885, 255467: 886, 11797: 887, 55090: 888, 110598: 889, 192069: 890, 152517: 891, 221925: 892, 78140: 893, 238296: 894, 71626: 895, 85739: 896, 245479: 897, 209749: 898, 204726: 899, 219514: 900, 61276: 901, 174314: 902, 186667: 903, 136114: 904, 252961: 905, 158201: 906, 139350: 907, 229866: 908, 172630: 909, 70246: 910, 232958: 911, 238645: 912, 97271: 913, 70784: 914, 101015: 915, 173522: 916, 242952: 917, 58199: 918, 132965: 919, 166119: 920, 70659: 921, 217480: 922, 69769: 923, 12546: 924, 237079: 925, 182152: 926, 213516: 927, 25159: 928, 6848: 929, 191615: 930, 5476: 931, 131001: 932, 75532: 933, 177252: 934, 198666: 935, 124010: 936, 27608: 937, 92192: 938, 113679: 939, 81554: 940, 220458: 941, 142251: 942, 66685: 943, 153200: 944, 95294: 945, 202177: 946, 220236: 947, 127253: 948, 37904: 949, 240347: 950, 125547: 951, 198352: 952, 110967: 953, 201607: 954, 219796: 955, 256751: 956, 78589: 957, 74088: 958, 24162: 959, 235247: 960, 153503: 961, 108846: 962}\n",
      "Step 1\n",
      "Step 2\n",
      "Step 3\n",
      "Step 3.5\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading checkins\")\n",
    "checkin_cols = ['user_id', 'poi_id', 'timestamp', 'timezone']\n",
    "checkins = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\Den_checkins.csv', sep=',', names=checkin_cols, encoding='latin-1').dropna(axis=1)\n",
    "\n",
    "print(\"Loading POIs\")\n",
    "venue_cols = ['poi_id', 'latitude', 'longitude', 'category', 'country_code']\n",
    "pois = pd.read_csv(r'C:\\Users\\lasse\\Desktop\\RecommenderDL\\datasets\\Den_pois.csv', sep=',', names=venue_cols, encoding='latin-1')\n",
    "\n",
    "c = pd.DataFrame(checkins, columns=['user_id', 'poi_id'])\n",
    "p = pd.DataFrame(pois, columns=['poi_id', 'latitude', 'longitude', 'category'])\n",
    "\n",
    "cp = p.merge(c, on='poi_id')\n",
    "\n",
    "#One checkin for each user\n",
    "users = checkins.copy()\n",
    "users.drop_duplicates(subset=\"user_id\", keep = 'first', inplace = True)\n",
    "print(\"Checkins: \", len(checkins))\n",
    "print(\"Users: \", len(users))\n",
    "len_checkins = len(checkins)\n",
    "len_users = len(users)\n",
    "\n",
    "#The rest of the checkins and categories\n",
    "checkins_rest = users.merge(checkins, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='right_only']\n",
    "print(\"Gotten: \", len(checkins_rest))\n",
    "\n",
    "#One of each category in checkins_rest\n",
    "categories1 = pd.DataFrame(pois, columns=['poi_id', 'category'])\n",
    "categories1 = checkins_rest.merge(categories1, on='poi_id')\n",
    "users_categories1 = categories1.copy()\n",
    "users_categories1.drop_duplicates(subset=\"category\", keep = 'first', inplace = True)\n",
    "print(\"Unique categories in checkins_rest: \", len(users_categories1))\n",
    "\n",
    "#FINISHING NOTE: Vi vil have alle colplement af checkins_rest, når vi sammenligner med categories_cat_no_cat, så har vi de 3 gange checkins vi har brug for. Så kan vi lave train/test på det store af dem.\n",
    "categories_cat_no_cat = pd.DataFrame(users_categories1, columns=['user_id', 'poi_id', 'timestamp', 'timezone', 'category'])\n",
    "checkins_rest_no_merge = pd.DataFrame(checkins_rest, columns=['user_id', 'poi_id', 'timestamp', 'timezone'])\n",
    "poisandcategories = pd.DataFrame(pois, columns=['poi_id', 'category'])\n",
    "checkins_rest_no_merge = checkins_rest_no_merge.merge(poisandcategories, on='poi_id')\n",
    "print(\"Total categories: \", len(categories_cat_no_cat))\n",
    "\n",
    "test = categories_cat_no_cat.merge(checkins_rest_no_merge, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='right_only']\n",
    "#test = pd.DataFrame(checkins_rest, columns=['user_id', 'poi_id', 'timestamp', 'timezone'])\n",
    "#cattest = pd.DataFrame(pois, columns=['poi_id', 'category'])\n",
    "#test.merge(cattest, on='poi_id')\n",
    "#checkins_rest = cattest.merge(test, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='right_only']\n",
    "\n",
    "restset = pd.DataFrame(test, columns=['user_id', 'poi_id', 'timestamp', 'timezone'])\n",
    "userset = users\n",
    "categoryset = pd.DataFrame(users_categories1, columns=['user_id', 'poi_id', 'timestamp', 'timezone'])\n",
    "\n",
    "print(\"Overview:\")\n",
    "print(len(userset))\n",
    "print(len(categoryset))\n",
    "print(len(restset))\n",
    "\n",
    "encoding = pd.DataFrame(userset, columns=['user_id'])\n",
    "encoding_array = {}\n",
    "temp = 0\n",
    "for user in encoding.iterrows():\n",
    "    user = user[0]\n",
    "    value = encoding._get_value(user, 'user_id')\n",
    "    encoding_array[value] = temp\n",
    "    temp += 1\n",
    "\n",
    "print(encoding_array)\n",
    "    \n",
    "###################################\n",
    "###################################\n",
    "####### Iteration 1: User #########\n",
    "###################################\n",
    "###################################\n",
    "\n",
    "print(\"Step 1\")\n",
    "checkin_data = categoryset.merge(pois, on='poi_id')\n",
    "#checkin_data.drop_duplicates(subset=\"user_id\", keep = 'first', inplace = True)\n",
    "\n",
    "df = checkin_data.set_index('user_id').poi_id.str.get_dummies(',')\n",
    "df = df.groupby('user_id').max()\n",
    "\n",
    "print(\"Step 2\")\n",
    "checkin_data_no_duplicates = checkin_data.copy()\n",
    "checkin_data_no_duplicates.drop_duplicates(subset =\"poi_id\", keep = 'first', inplace = True)\n",
    "checkin_data_no_duplicates = pd.DataFrame(checkin_data_no_duplicates, columns = ['poi_id', 'category'])\n",
    "\n",
    "#Extract categorical data\n",
    "print(\"Step 3\")\n",
    "categories = pd.DataFrame(checkin_data, columns=['category'])\n",
    "categories.drop_duplicates(subset =\"category\", keep = 'first', inplace = True)\n",
    "category_length = len(categories)\n",
    "categories_numpy = categories.to_numpy()\n",
    "\n",
    "\n",
    "#Extracting all of the users and the pois\n",
    "\n",
    "print(\"Step 3.5\")\n",
    "listofusers = pd.DataFrame(checkin_data, columns= ['user_id']).groupby('user_id').max().sample(frac=1)\n",
    "listofpois = pd.DataFrame(checkin_data, columns= ['poi_id', 'latitude', 'longitude']).groupby('poi_id').max().sample(frac=1)\n",
    "userarray = listofusers.index.to_numpy()\n",
    "poiarray = listofpois.index.to_numpy()\n",
    "userdataframe = pd.DataFrame(userarray, columns = ['Users'])\n",
    "poidataframe = pd.DataFrame(poiarray, columns = ['Poi'])\n",
    "dot = userdataframe.merge(poidataframe, how='cross')\n",
    "\n",
    "print(\"Step 4\")\n",
    "\n",
    "rows_list = []\n",
    "for i in range(len(dot)):\n",
    "    temp = dot.loc[i, \"Poi\"]\n",
    "    latitude = listofpois.loc[temp]['latitude']\n",
    "    longitude = listofpois.loc[temp]['longitude']\n",
    "    dict1 = {'latitude':latitude, 'longitude':longitude}\n",
    "    rows_list.append(dict1)\n",
    "    #latitude = poiarray[i]\n",
    "latlong = pd.DataFrame(rows_list)\n",
    "\n",
    "#Creating dataset\n",
    "print(\"Step 5\")\n",
    "userdot = pd.DataFrame(dot, columns= ['Users'])\n",
    "latlong['latitude'] = pd.to_numeric(latlong['latitude'])\n",
    "latlong['longitude'] = pd.to_numeric(latlong['longitude'])\n",
    "dataset = pd.concat([userdot, latlong], axis=1)\n",
    "\n",
    "print(\"Step 6\")\n",
    "rows_list = []\n",
    "category_list = []\n",
    "groundtruth = 0\n",
    "for i in range(len(dot)):\n",
    "    temp = cp.loc[(cp['poi_id'] == dot.loc[i, \"Poi\"]) & (cp['user_id'] == dot.loc[i, \"Users\"])]\n",
    "    if temp.empty:\n",
    "        groundtruth = 0\n",
    "    else:\n",
    "        groundtruth = 1\n",
    "    #temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    #temp = df[dot.loc[i, \"Poi\"]][dot.loc[i, \"Users\"]]\n",
    "    dict1 = {'ground_truth':float(groundtruth)}\n",
    "    rows_list.append(dict1)\n",
    "    #Extract category from the list\n",
    "    category = checkin_data_no_duplicates.loc[checkin_data_no_duplicates['poi_id'] == dot.loc[i, \"Poi\"]]\n",
    "    cat = category['category']\n",
    "    index = np.where(categories_numpy == [cat])[0][0]\n",
    "    category_list.append(index)\n",
    "#category_label = \n",
    "groundtruth = pd.DataFrame(rows_list)\n",
    "#result = pd.concat([dot, groundtruth], axis=1)\n",
    "\n",
    "print(\"Step 7\")\n",
    "datasetst = pd.concat([dataset, groundtruth], axis=1)\n",
    "categories = pd.DataFrame(category_list, columns=['category'])\n",
    "datasetstst = pd.concat([datasetst, categories], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f8a3b74-a68d-47b4-8098-ee422e149da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8\n",
      "Step 9\n",
      "Step 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 8\")\n",
    "dataset_numpy = datasetstst.to_numpy()\n",
    "\n",
    "labels = pd.DataFrame(category_list, columns=['ground_truth'])\n",
    "labels_numpy = labels.to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_numpy, labels_numpy, test_size=0.05, random_state=0)\n",
    "\n",
    "print(\"Step 9\")\n",
    "x_train_df = pd.DataFrame(x_train, columns=['Users', 'latitude', 'longitude', 'ground_truth', 'category'])\n",
    "x_test_df = pd.DataFrame(x_test, columns=['Users', 'latitude', 'longitude', 'ground_truth', 'category'])\n",
    "\n",
    "x_test_df.to_csv(r'/user/student.aau.dk/lharde18/Data-output/Den/y_train_df.csv', sep=',', index=['User','Latitude','Longitude', '0'])\n",
    "\n",
    "for index, row in x_train_df.iterrows():\n",
    "    usr = x_train_df.loc[index, 'Users']\n",
    "    x_train_df.xs(index)['Users']=encoding_array.get(usr)\n",
    "\n",
    "users = pd.DataFrame(x_train_df, columns=['Users'])\n",
    "lat = pd.DataFrame(x_train_df, columns=['latitude'])\n",
    "long = pd.DataFrame(x_train_df, columns=['longitude'])\n",
    "cat = pd.DataFrame(x_train_df, columns=['category'])\n",
    "labels = pd.DataFrame(x_train_df, columns=['ground_truth'])\n",
    "    \n",
    "print(\"Step 10\")\n",
    "users = tf.convert_to_tensor(\n",
    "    users, dtype=None, dtype_hint=None, name=None)\n",
    "lat = tf.convert_to_tensor(\n",
    "    lat, dtype=None, dtype_hint=None, name=None)\n",
    "long = tf.convert_to_tensor(\n",
    "    long, dtype=None, dtype_hint=None, name=None)\n",
    "cat = tf.convert_to_tensor(\n",
    "    cat, dtype='int64', dtype_hint=None, name=None)\n",
    "labels = tf.convert_to_tensor(\n",
    "    labels, dtype=None, dtype_hint=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b9a2ef6-07dc-45c8-b1df-e0836a03bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n",
      "Model: \"functional_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "poi_latitude (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "poi_longitude (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 2)            0           poi_latitude[0][0]               \n",
      "                                                                 poi_longitude[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "category_input (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          384         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 1, 128)       35712       category_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 128)       0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 1, 256)       0           embedding_28[0][0]               \n",
      "                                                                 reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1, 256)       7070976     user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, 1, 1)         0           concatenate_29[0][0]             \n",
      "                                                                 embedding_29[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,107,072\n",
      "Trainable params: 7,107,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "27621\n",
      "Epoch 1/25\n",
      "Tensor(\"functional_29/dot_14/MatMul:0\", shape=(27, 1, 1), dtype=float32)\n",
      "Tensor(\"functional_29/dot_14/MatMul:0\", shape=(27, 1, 1), dtype=float32)\n",
      " 116/1023 [==>...........................] - ETA: 1:08 - loss: 0.7964"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-402ac9c17c73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#Train_data, [dataset.user_id, dataset.poi_id]. Label: ground_truth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(category_length)\n",
    "model = EmbModel(len(users), category_length)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "\n",
    "model.compile(\n",
    "    optimizer\n",
    ")\n",
    "\n",
    "#Train_data, [dataset.user_id, dataset.poi_id]. Label: ground_truth\n",
    "model.fit([cat, lat, long, users], labels, epochs = 25, batch_size=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b55681-fe1d-4018-8aa0-09b70be5b5a6",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
